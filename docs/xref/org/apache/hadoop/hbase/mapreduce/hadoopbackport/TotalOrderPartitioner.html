<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<title>TotalOrderPartitioner xref</title>
<link type="text/css" rel="stylesheet" href="../../../../../../stylesheet.css" />
</head>
<body>
<div id="overview"><a href="../../../../../../../apidocs/org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">View Javadoc</a></div><pre>

<a name="1" href="#1">1</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2" href="#2">2</a>   <em class="jxr_javadoccomment"> * Licensed to the Apache Software Foundation (ASF) under one</em>
<a name="3" href="#3">3</a>   <em class="jxr_javadoccomment"> * or more contributor license agreements.  See the NOTICE file</em>
<a name="4" href="#4">4</a>   <em class="jxr_javadoccomment"> * distributed with this work for additional information</em>
<a name="5" href="#5">5</a>   <em class="jxr_javadoccomment"> * regarding copyright ownership.  The ASF licenses this file</em>
<a name="6" href="#6">6</a>   <em class="jxr_javadoccomment"> * to you under the Apache License, Version 2.0 (the</em>
<a name="7" href="#7">7</a>   <em class="jxr_javadoccomment"> * "License"); you may not use this file except in compliance</em>
<a name="8" href="#8">8</a>   <em class="jxr_javadoccomment"> * with the License.  You may obtain a copy of the License at</em>
<a name="9" href="#9">9</a>   <em class="jxr_javadoccomment"> *</em>
<a name="10" href="#10">10</a>  <em class="jxr_javadoccomment"> *     <a href="http://www.apache.org/licenses/LICENSE-2.0" target="alexandria_uri">http://www.apache.org/licenses/LICENSE-2.0</a></em>
<a name="11" href="#11">11</a>  <em class="jxr_javadoccomment"> *</em>
<a name="12" href="#12">12</a>  <em class="jxr_javadoccomment"> * Unless required by applicable law or agreed to in writing, software</em>
<a name="13" href="#13">13</a>  <em class="jxr_javadoccomment"> * distributed under the License is distributed on an "AS IS" BASIS,</em>
<a name="14" href="#14">14</a>  <em class="jxr_javadoccomment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</em>
<a name="15" href="#15">15</a>  <em class="jxr_javadoccomment"> * See the License for the specific language governing permissions and</em>
<a name="16" href="#16">16</a>  <em class="jxr_javadoccomment"> * limitations under the License.</em>
<a name="17" href="#17">17</a>  <em class="jxr_javadoccomment"> */</em>
<a name="18" href="#18">18</a>  <strong class="jxr_keyword">package</strong> org.apache.hadoop.hbase.mapreduce.hadoopbackport;
<a name="19" href="#19">19</a>  
<a name="20" href="#20">20</a>  <strong class="jxr_keyword">import</strong> java.io.IOException;
<a name="21" href="#21">21</a>  <strong class="jxr_keyword">import</strong> java.lang.reflect.Array;
<a name="22" href="#22">22</a>  <strong class="jxr_keyword">import</strong> java.util.ArrayList;
<a name="23" href="#23">23</a>  <strong class="jxr_keyword">import</strong> java.util.Arrays;
<a name="24" href="#24">24</a>  
<a name="25" href="#25">25</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.conf.Configurable;
<a name="26" href="#26">26</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.conf.Configuration;
<a name="27" href="#27">27</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileSystem;
<a name="28" href="#28">28</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.Path;
<a name="29" href="#29">29</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.BinaryComparable;
<a name="30" href="#30">30</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.NullWritable;
<a name="31" href="#31">31</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.SequenceFile;
<a name="32" href="#32">32</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.RawComparator;
<a name="33" href="#33">33</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.WritableComparable;
<a name="34" href="#34">34</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.Job;
<a name="35" href="#35">35</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.Partitioner;
<a name="36" href="#36">36</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.util.ReflectionUtils;
<a name="37" href="#37">37</a>  
<a name="38" href="#38">38</a>  <em class="jxr_javadoccomment">/**</em>
<a name="39" href="#39">39</a>  <em class="jxr_javadoccomment"> * Partitioner effecting a total order by reading split points from</em>
<a name="40" href="#40">40</a>  <em class="jxr_javadoccomment"> * an externally generated source.</em>
<a name="41" href="#41">41</a>  <em class="jxr_javadoccomment"> * </em>
<a name="42" href="#42">42</a>  <em class="jxr_javadoccomment"> * This is an identical copy of o.a.h.mapreduce.lib.partition.TotalOrderPartitioner</em>
<a name="43" href="#43">43</a>  <em class="jxr_javadoccomment"> * from Hadoop trunk at r910774.</em>
<a name="44" href="#44">44</a>  <em class="jxr_javadoccomment"> */</em>
<a name="45" href="#45">45</a>  <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">class</strong> TotalOrderPartitioner&lt;K <strong class="jxr_keyword">extends</strong> WritableComparable&lt;?&gt;,V&gt;
<a name="46" href="#46">46</a>      <strong class="jxr_keyword">extends</strong> Partitioner&lt;K,V&gt; implements Configurable {
<a name="47" href="#47">47</a>  
<a name="48" href="#48">48</a>    <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">Node</a> partitions;
<a name="49" href="#49">49</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String DEFAULT_PATH = <span class="jxr_string">"_partition.lst"</span>;
<a name="50" href="#50">50</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String PARTITIONER_PATH = 
<a name="51" href="#51">51</a>      <span class="jxr_string">"mapreduce.totalorderpartitioner.path"</span>;
<a name="52" href="#52">52</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String MAX_TRIE_DEPTH = 
<a name="53" href="#53">53</a>      <span class="jxr_string">"mapreduce.totalorderpartitioner.trie.maxdepth"</span>; 
<a name="54" href="#54">54</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String NATURAL_ORDER = 
<a name="55" href="#55">55</a>      <span class="jxr_string">"mapreduce.totalorderpartitioner.naturalorder"</span>;
<a name="56" href="#56">56</a>    Configuration conf;
<a name="57" href="#57">57</a>  
<a name="58" href="#58">58</a>    <strong class="jxr_keyword">public</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TotalOrderPartitioner</a>() { }
<a name="59" href="#59">59</a>  
<a name="60" href="#60">60</a>    <em class="jxr_javadoccomment">/**</em>
<a name="61" href="#61">61</a>  <em class="jxr_javadoccomment">   * Read in the partition file and build indexing data structures.</em>
<a name="62" href="#62">62</a>  <em class="jxr_javadoccomment">   * If the keytype is {@link org.apache.hadoop.io.BinaryComparable} and</em>
<a name="63" href="#63">63</a>  <em class="jxr_javadoccomment">   * &lt;tt&gt;total.order.partitioner.natural.order&lt;/tt&gt; is not false, a trie</em>
<a name="64" href="#64">64</a>  <em class="jxr_javadoccomment">   * of the first &lt;tt&gt;total.order.partitioner.max.trie.depth&lt;/tt&gt;(2) + 1 bytes</em>
<a name="65" href="#65">65</a>  <em class="jxr_javadoccomment">   * will be built. Otherwise, keys will be located using a binary search of</em>
<a name="66" href="#66">66</a>  <em class="jxr_javadoccomment">   * the partition keyset using the {@link org.apache.hadoop.io.RawComparator}</em>
<a name="67" href="#67">67</a>  <em class="jxr_javadoccomment">   * defined for this job. The input file must be sorted with the same</em>
<a name="68" href="#68">68</a>  <em class="jxr_javadoccomment">   * comparator and contain {@link Job#getNumReduceTasks()} - 1 keys.</em>
<a name="69" href="#69">69</a>  <em class="jxr_javadoccomment">   */</em>
<a name="70" href="#70">70</a>    @SuppressWarnings(<span class="jxr_string">"unchecked"</span>) <em class="jxr_comment">// keytype from conf not static</em>
<a name="71" href="#71">71</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> setConf(Configuration conf) {
<a name="72" href="#72">72</a>      <strong class="jxr_keyword">try</strong> {
<a name="73" href="#73">73</a>        <strong class="jxr_keyword">this</strong>.conf = conf;
<a name="74" href="#74">74</a>        String parts = getPartitionFile(conf);
<a name="75" href="#75">75</a>        <strong class="jxr_keyword">final</strong> Path partFile = <strong class="jxr_keyword">new</strong> Path(parts);
<a name="76" href="#76">76</a>        <strong class="jxr_keyword">final</strong> FileSystem fs = (DEFAULT_PATH.equals(parts))
<a name="77" href="#77">77</a>          ? FileSystem.getLocal(conf)     <em class="jxr_comment">// assume in DistributedCache</em>
<a name="78" href="#78">78</a>          : partFile.getFileSystem(conf);
<a name="79" href="#79">79</a>  
<a name="80" href="#80">80</a>        Job job = <strong class="jxr_keyword">new</strong> Job(conf);
<a name="81" href="#81">81</a>        Class&lt;K&gt; keyClass = (Class&lt;K&gt;)job.getMapOutputKeyClass();
<a name="82" href="#82">82</a>        K[] splitPoints = readPartitions(fs, partFile, keyClass, conf);
<a name="83" href="#83">83</a>        <strong class="jxr_keyword">if</strong> (splitPoints.length != job.getNumReduceTasks() - 1) {
<a name="84" href="#84">84</a>          <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Wrong number of partitions in keyset:"</span>
<a name="85" href="#85">85</a>              + splitPoints.length);
<a name="86" href="#86">86</a>        }
<a name="87" href="#87">87</a>        RawComparator&lt;K&gt; comparator =
<a name="88" href="#88">88</a>          (RawComparator&lt;K&gt;) job.getSortComparator();
<a name="89" href="#89">89</a>        <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 0; i &lt; splitPoints.length - 1; ++i) {
<a name="90" href="#90">90</a>          <strong class="jxr_keyword">if</strong> (comparator.compare(splitPoints[i], splitPoints[i+1]) &gt;= 0) {
<a name="91" href="#91">91</a>            <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Split points are out of order"</span>);
<a name="92" href="#92">92</a>          }
<a name="93" href="#93">93</a>        }
<a name="94" href="#94">94</a>        <strong class="jxr_keyword">boolean</strong> natOrder =
<a name="95" href="#95">95</a>          conf.getBoolean(NATURAL_ORDER, <strong class="jxr_keyword">true</strong>);
<a name="96" href="#96">96</a>        <strong class="jxr_keyword">if</strong> (natOrder &amp;&amp; BinaryComparable.<strong class="jxr_keyword">class</strong>.isAssignableFrom(keyClass)) {
<a name="97" href="#97">97</a>          partitions = buildTrie((BinaryComparable[])splitPoints, 0,
<a name="98" href="#98">98</a>              splitPoints.length, <strong class="jxr_keyword">new</strong> byte[0],
<a name="99" href="#99">99</a>              <em class="jxr_comment">// Now that blocks of identical splitless trie nodes are </em>
<a name="100" href="#100">100</a>             <em class="jxr_comment">// represented reentrantly, and we develop a leaf for any trie</em>
<a name="101" href="#101">101</a>             <em class="jxr_comment">// node with only one split point, the only reason for a depth</em>
<a name="102" href="#102">102</a>             <em class="jxr_comment">// limit is to refute stack overflow or bloat in the pathological</em>
<a name="103" href="#103">103</a>             <em class="jxr_comment">// case where the split points are long and mostly look like bytes </em>
<a name="104" href="#104">104</a>             <em class="jxr_comment">// iii...iixii...iii   .  Therefore, we make the default depth</em>
<a name="105" href="#105">105</a>             <em class="jxr_comment">// limit large but not huge.</em>
<a name="106" href="#106">106</a>             conf.getInt(MAX_TRIE_DEPTH, 200));
<a name="107" href="#107">107</a>       } <strong class="jxr_keyword">else</strong> {
<a name="108" href="#108">108</a>         partitions = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">BinarySearchNode</a>(splitPoints, comparator);
<a name="109" href="#109">109</a>       }
<a name="110" href="#110">110</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="111" href="#111">111</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IllegalArgumentException(<span class="jxr_string">"Can't read partitions file"</span>, e);
<a name="112" href="#112">112</a>     }
<a name="113" href="#113">113</a>   }
<a name="114" href="#114">114</a> 
<a name="115" href="#115">115</a>   <strong class="jxr_keyword">public</strong> Configuration getConf() {
<a name="116" href="#116">116</a>     <strong class="jxr_keyword">return</strong> conf;
<a name="117" href="#117">117</a>   }
<a name="118" href="#118">118</a>   
<a name="119" href="#119">119</a>   <em class="jxr_comment">// by construction, we know if our keytype</em>
<a name="120" href="#120">120</a>   @SuppressWarnings(<span class="jxr_string">"unchecked"</span>) <em class="jxr_comment">// is memcmp-able and uses the trie</em>
<a name="121" href="#121">121</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> getPartition(K key, V value, <strong class="jxr_keyword">int</strong> numPartitions) {
<a name="122" href="#122">122</a>     <strong class="jxr_keyword">return</strong> partitions.findPartition(key);
<a name="123" href="#123">123</a>   }
<a name="124" href="#124">124</a> 
<a name="125" href="#125">125</a>   <em class="jxr_javadoccomment">/**</em>
<a name="126" href="#126">126</a> <em class="jxr_javadoccomment">   * Set the path to the SequenceFile storing the sorted partition keyset.</em>
<a name="127" href="#127">127</a> <em class="jxr_javadoccomment">   * It must be the case that for &lt;tt&gt;R&lt;/tt&gt; reduces, there are &lt;tt&gt;R-1&lt;/tt&gt;</em>
<a name="128" href="#128">128</a> <em class="jxr_javadoccomment">   * keys in the SequenceFile.</em>
<a name="129" href="#129">129</a> <em class="jxr_javadoccomment">   */</em>
<a name="130" href="#130">130</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> setPartitionFile(Configuration conf, Path p) {
<a name="131" href="#131">131</a>     conf.set(PARTITIONER_PATH, p.toString());
<a name="132" href="#132">132</a>   }
<a name="133" href="#133">133</a> 
<a name="134" href="#134">134</a>   <em class="jxr_javadoccomment">/**</em>
<a name="135" href="#135">135</a> <em class="jxr_javadoccomment">   * Get the path to the SequenceFile storing the sorted partition keyset.</em>
<a name="136" href="#136">136</a> <em class="jxr_javadoccomment">   * @see #setPartitionFile(Configuration, Path)</em>
<a name="137" href="#137">137</a> <em class="jxr_javadoccomment">   */</em>
<a name="138" href="#138">138</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> String getPartitionFile(Configuration conf) {
<a name="139" href="#139">139</a>     <strong class="jxr_keyword">return</strong> conf.get(PARTITIONER_PATH, DEFAULT_PATH);
<a name="140" href="#140">140</a>   }
<a name="141" href="#141">141</a> 
<a name="142" href="#142">142</a>   <em class="jxr_javadoccomment">/**</em>
<a name="143" href="#143">143</a> <em class="jxr_javadoccomment">   * Interface to the partitioner to locate a key in the partition keyset.</em>
<a name="144" href="#144">144</a> <em class="jxr_javadoccomment">   */</em>
<a name="145" href="#145">145</a>   <strong class="jxr_keyword">interface</strong> Node&lt;T&gt; {
<a name="146" href="#146">146</a>     <em class="jxr_javadoccomment">/**</em>
<a name="147" href="#147">147</a> <em class="jxr_javadoccomment">     * Locate partition in keyset K, st [Ki..Ki+1) defines a partition,</em>
<a name="148" href="#148">148</a> <em class="jxr_javadoccomment">     * with implicit K0 = -inf, Kn = +inf, and |K| = #partitions - 1.</em>
<a name="149" href="#149">149</a> <em class="jxr_javadoccomment">     */</em>
<a name="150" href="#150">150</a>     <strong class="jxr_keyword">int</strong> findPartition(T key);
<a name="151" href="#151">151</a>   }
<a name="152" href="#152">152</a> 
<a name="153" href="#153">153</a>   <em class="jxr_javadoccomment">/**</em>
<a name="154" href="#154">154</a> <em class="jxr_javadoccomment">   * Base class for trie nodes. If the keytype is memcomp-able, this builds</em>
<a name="155" href="#155">155</a> <em class="jxr_javadoccomment">   * tries of the first &lt;tt&gt;total.order.partitioner.max.trie.depth&lt;/tt&gt;</em>
<a name="156" href="#156">156</a> <em class="jxr_javadoccomment">   * bytes.</em>
<a name="157" href="#157">157</a> <em class="jxr_javadoccomment">   */</em>
<a name="158" href="#158">158</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">abstract</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> implements Node&lt;BinaryComparable&gt; {
<a name="159" href="#159">159</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> level;
<a name="160" href="#160">160</a>     <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a>(<strong class="jxr_keyword">int</strong> level) {
<a name="161" href="#161">161</a>       <strong class="jxr_keyword">this</strong>.level = level;
<a name="162" href="#162">162</a>     }
<a name="163" href="#163">163</a>     <strong class="jxr_keyword">int</strong> getLevel() {
<a name="164" href="#164">164</a>       <strong class="jxr_keyword">return</strong> level;
<a name="165" href="#165">165</a>     }
<a name="166" href="#166">166</a>   }
<a name="167" href="#167">167</a> 
<a name="168" href="#168">168</a>   <em class="jxr_javadoccomment">/**</em>
<a name="169" href="#169">169</a> <em class="jxr_javadoccomment">   * For types that are not {@link org.apache.hadoop.io.BinaryComparable} or</em>
<a name="170" href="#170">170</a> <em class="jxr_javadoccomment">   * where disabled by &lt;tt&gt;total.order.partitioner.natural.order&lt;/tt&gt;,</em>
<a name="171" href="#171">171</a> <em class="jxr_javadoccomment">   * search the partition keyset with a binary search.</em>
<a name="172" href="#172">172</a> <em class="jxr_javadoccomment">   */</em>
<a name="173" href="#173">173</a>   <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">BinarySearchNode</a> implements Node&lt;K&gt; {
<a name="174" href="#174">174</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> K[] splitPoints;
<a name="175" href="#175">175</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> RawComparator&lt;K&gt; comparator;
<a name="176" href="#176">176</a>     <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">BinarySearchNode</a>(K[] splitPoints, RawComparator&lt;K&gt; comparator) {
<a name="177" href="#177">177</a>       <strong class="jxr_keyword">this</strong>.splitPoints = splitPoints;
<a name="178" href="#178">178</a>       <strong class="jxr_keyword">this</strong>.comparator = comparator;
<a name="179" href="#179">179</a>     }
<a name="180" href="#180">180</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> findPartition(K key) {
<a name="181" href="#181">181</a>       <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> pos = Arrays.binarySearch(splitPoints, key, comparator) + 1;
<a name="182" href="#182">182</a>       <strong class="jxr_keyword">return</strong> (pos &lt; 0) ? -pos : pos;
<a name="183" href="#183">183</a>     }
<a name="184" href="#184">184</a>   }
<a name="185" href="#185">185</a> 
<a name="186" href="#186">186</a>   <em class="jxr_javadoccomment">/**</em>
<a name="187" href="#187">187</a> <em class="jxr_javadoccomment">   * An inner trie node that contains 256 children based on the next</em>
<a name="188" href="#188">188</a> <em class="jxr_javadoccomment">   * character.</em>
<a name="189" href="#189">189</a> <em class="jxr_javadoccomment">   */</em>
<a name="190" href="#190">190</a>   <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">InnerTrieNode</a> <strong class="jxr_keyword">extends</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> {
<a name="191" href="#191">191</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a>[] child = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a>[256];
<a name="192" href="#192">192</a> 
<a name="193" href="#193">193</a>     <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">InnerTrieNode</a>(<strong class="jxr_keyword">int</strong> level) {
<a name="194" href="#194">194</a>       <strong class="jxr_keyword">super</strong>(level);
<a name="195" href="#195">195</a>     }
<a name="196" href="#196">196</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> findPartition(BinaryComparable key) {
<a name="197" href="#197">197</a>       <strong class="jxr_keyword">int</strong> level = getLevel();
<a name="198" href="#198">198</a>       <strong class="jxr_keyword">if</strong> (key.getLength() &lt;= level) {
<a name="199" href="#199">199</a>         <strong class="jxr_keyword">return</strong> child[0].findPartition(key);
<a name="200" href="#200">200</a>       }
<a name="201" href="#201">201</a>       <strong class="jxr_keyword">return</strong> child[0xFF &amp; key.getBytes()[level]].findPartition(key);
<a name="202" href="#202">202</a>     }
<a name="203" href="#203">203</a>   }
<a name="204" href="#204">204</a>   
<a name="205" href="#205">205</a>   <em class="jxr_javadoccomment">/**</em>
<a name="206" href="#206">206</a> <em class="jxr_javadoccomment">   * @param level        the tree depth at this node</em>
<a name="207" href="#207">207</a> <em class="jxr_javadoccomment">   * @param splitPoints  the full split point vector, which holds</em>
<a name="208" href="#208">208</a> <em class="jxr_javadoccomment">   *                     the split point or points this leaf node</em>
<a name="209" href="#209">209</a> <em class="jxr_javadoccomment">   *                     should contain</em>
<a name="210" href="#210">210</a> <em class="jxr_javadoccomment">   * @param lower        first INcluded element of splitPoints</em>
<a name="211" href="#211">211</a> <em class="jxr_javadoccomment">   * @param upper        first EXcluded element of splitPoints</em>
<a name="212" href="#212">212</a> <em class="jxr_javadoccomment">   * @return  a leaf node.  They come in three kinds: no split points </em>
<a name="213" href="#213">213</a> <em class="jxr_javadoccomment">   *          [and the findParttion returns a canned index], one split</em>
<a name="214" href="#214">214</a> <em class="jxr_javadoccomment">   *          point [and we compare with a single comparand], or more</em>
<a name="215" href="#215">215</a> <em class="jxr_javadoccomment">   *          than one [and we do a binary search].  The last case is</em>
<a name="216" href="#216">216</a> <em class="jxr_javadoccomment">   *          rare.</em>
<a name="217" href="#217">217</a> <em class="jxr_javadoccomment">   */</em>
<a name="218" href="#218">218</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> LeafTrieNodeFactory
<a name="219" href="#219">219</a>              (<strong class="jxr_keyword">int</strong> level, BinaryComparable[] splitPoints, <strong class="jxr_keyword">int</strong> lower, <strong class="jxr_keyword">int</strong> upper) {
<a name="220" href="#220">220</a>       <strong class="jxr_keyword">switch</strong> (upper - lower) {
<a name="221" href="#221">221</a>       <strong class="jxr_keyword">case</strong> 0:
<a name="222" href="#222">222</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">UnsplitTrieNode</a>(level, lower);
<a name="223" href="#223">223</a>           
<a name="224" href="#224">224</a>       <strong class="jxr_keyword">case</strong> 1:
<a name="225" href="#225">225</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">SinglySplitTrieNode</a>(level, splitPoints, lower);
<a name="226" href="#226">226</a>           
<a name="227" href="#227">227</a>       <strong class="jxr_keyword">default</strong>:
<a name="228" href="#228">228</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">LeafTrieNode</a>(level, splitPoints, lower, upper);
<a name="229" href="#229">229</a>       }
<a name="230" href="#230">230</a>   }
<a name="231" href="#231">231</a> 
<a name="232" href="#232">232</a>   <em class="jxr_javadoccomment">/**</em>
<a name="233" href="#233">233</a> <em class="jxr_javadoccomment">   * A leaf trie node that scans for the key between lower..upper.</em>
<a name="234" href="#234">234</a> <em class="jxr_javadoccomment">   * </em>
<a name="235" href="#235">235</a> <em class="jxr_javadoccomment">   * We don't generate many of these now, since we usually continue trie-ing </em>
<a name="236" href="#236">236</a> <em class="jxr_javadoccomment">   * when more than one split point remains at this level. and we make different</em>
<a name="237" href="#237">237</a> <em class="jxr_javadoccomment">   * objects for nodes with 0 or 1 split point.</em>
<a name="238" href="#238">238</a> <em class="jxr_javadoccomment">   */</em>
<a name="239" href="#239">239</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">LeafTrieNode</a> <strong class="jxr_keyword">extends</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> {
<a name="240" href="#240">240</a>     <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> lower;
<a name="241" href="#241">241</a>     <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> upper;
<a name="242" href="#242">242</a>     <strong class="jxr_keyword">final</strong> BinaryComparable[] splitPoints;
<a name="243" href="#243">243</a>     <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">LeafTrieNode</a>(<strong class="jxr_keyword">int</strong> level, BinaryComparable[] splitPoints, <strong class="jxr_keyword">int</strong> lower, <strong class="jxr_keyword">int</strong> upper) {
<a name="244" href="#244">244</a>       <strong class="jxr_keyword">super</strong>(level);
<a name="245" href="#245">245</a>       <strong class="jxr_keyword">this</strong>.lower = lower;
<a name="246" href="#246">246</a>       <strong class="jxr_keyword">this</strong>.upper = upper;
<a name="247" href="#247">247</a>       <strong class="jxr_keyword">this</strong>.splitPoints = splitPoints;
<a name="248" href="#248">248</a>     }
<a name="249" href="#249">249</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> findPartition(BinaryComparable key) {
<a name="250" href="#250">250</a>       <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> pos = Arrays.binarySearch(splitPoints, lower, upper, key) + 1;
<a name="251" href="#251">251</a>       <strong class="jxr_keyword">return</strong> (pos &lt; 0) ? -pos : pos;
<a name="252" href="#252">252</a>     }
<a name="253" href="#253">253</a>   }
<a name="254" href="#254">254</a>   
<a name="255" href="#255">255</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">UnsplitTrieNode</a> <strong class="jxr_keyword">extends</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> {
<a name="256" href="#256">256</a>       <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> result;
<a name="257" href="#257">257</a>       
<a name="258" href="#258">258</a>       <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">UnsplitTrieNode</a>(<strong class="jxr_keyword">int</strong> level, <strong class="jxr_keyword">int</strong> value) {
<a name="259" href="#259">259</a>           <strong class="jxr_keyword">super</strong>(level);
<a name="260" href="#260">260</a>           <strong class="jxr_keyword">this</strong>.result = value;
<a name="261" href="#261">261</a>       }
<a name="262" href="#262">262</a>       
<a name="263" href="#263">263</a>       <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> findPartition(BinaryComparable key) {
<a name="264" href="#264">264</a>           <strong class="jxr_keyword">return</strong> result;
<a name="265" href="#265">265</a>       }
<a name="266" href="#266">266</a>   }
<a name="267" href="#267">267</a>   
<a name="268" href="#268">268</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">SinglySplitTrieNode</a> <strong class="jxr_keyword">extends</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> {
<a name="269" href="#269">269</a>       <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong>               lower;
<a name="270" href="#270">270</a>       <strong class="jxr_keyword">final</strong> BinaryComparable  mySplitPoint;
<a name="271" href="#271">271</a>       
<a name="272" href="#272">272</a>       <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">SinglySplitTrieNode</a>(<strong class="jxr_keyword">int</strong> level, BinaryComparable[] splitPoints, <strong class="jxr_keyword">int</strong> lower) {
<a name="273" href="#273">273</a>           <strong class="jxr_keyword">super</strong>(level);
<a name="274" href="#274">274</a>           <strong class="jxr_keyword">this</strong>.lower = lower;
<a name="275" href="#275">275</a>           <strong class="jxr_keyword">this</strong>.mySplitPoint = splitPoints[lower];
<a name="276" href="#276">276</a>       }
<a name="277" href="#277">277</a>       
<a name="278" href="#278">278</a>       <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> findPartition(BinaryComparable key) {
<a name="279" href="#279">279</a>           <strong class="jxr_keyword">return</strong> lower + (key.compareTo(mySplitPoint) &lt; 0 ? 0 : 1);
<a name="280" href="#280">280</a>       }
<a name="281" href="#281">281</a>   }
<a name="282" href="#282">282</a> 
<a name="283" href="#283">283</a> 
<a name="284" href="#284">284</a>   <em class="jxr_javadoccomment">/**</em>
<a name="285" href="#285">285</a> <em class="jxr_javadoccomment">   * Read the cut points from the given IFile.</em>
<a name="286" href="#286">286</a> <em class="jxr_javadoccomment">   * @param fs The file system</em>
<a name="287" href="#287">287</a> <em class="jxr_javadoccomment">   * @param p The path to read</em>
<a name="288" href="#288">288</a> <em class="jxr_javadoccomment">   * @param keyClass The map output key class</em>
<a name="289" href="#289">289</a> <em class="jxr_javadoccomment">   * @param job The job config</em>
<a name="290" href="#290">290</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="291" href="#291">291</a> <em class="jxr_javadoccomment">   */</em>
<a name="292" href="#292">292</a>                                  <em class="jxr_comment">// matching key types enforced by passing in</em>
<a name="293" href="#293">293</a>   @SuppressWarnings(<span class="jxr_string">"unchecked"</span>) <em class="jxr_comment">// map output key class</em>
<a name="294" href="#294">294</a>   <strong class="jxr_keyword">private</strong> K[] readPartitions(FileSystem fs, Path p, Class&lt;K&gt; keyClass,
<a name="295" href="#295">295</a>       Configuration conf) <strong class="jxr_keyword">throws</strong> IOException {
<a name="296" href="#296">296</a>     SequenceFile.Reader reader = <strong class="jxr_keyword">new</strong> SequenceFile.Reader(fs, p, conf);
<a name="297" href="#297">297</a>     ArrayList&lt;K&gt; parts = <strong class="jxr_keyword">new</strong> ArrayList&lt;K&gt;();
<a name="298" href="#298">298</a>     K key = ReflectionUtils.newInstance(keyClass, conf);
<a name="299" href="#299">299</a>     NullWritable value = NullWritable.get();
<a name="300" href="#300">300</a>     <strong class="jxr_keyword">while</strong> (reader.next(key, value)) {
<a name="301" href="#301">301</a>       parts.add(key);
<a name="302" href="#302">302</a>       key = ReflectionUtils.newInstance(keyClass, conf);
<a name="303" href="#303">303</a>     }
<a name="304" href="#304">304</a>     reader.close();
<a name="305" href="#305">305</a>     <strong class="jxr_keyword">return</strong> parts.toArray((K[])Array.newInstance(keyClass, parts.size()));
<a name="306" href="#306">306</a>   }
<a name="307" href="#307">307</a>   
<a name="308" href="#308">308</a>   <em class="jxr_javadoccomment">/**</em>
<a name="309" href="#309">309</a> <em class="jxr_javadoccomment">   * </em>
<a name="310" href="#310">310</a> <em class="jxr_javadoccomment">   * This object contains a TrieNodeRef if there is such a thing that</em>
<a name="311" href="#311">311</a> <em class="jxr_javadoccomment">   * can be repeated.  Two adjacent trie node slots that contain no </em>
<a name="312" href="#312">312</a> <em class="jxr_javadoccomment">   * split points can be filled with the same trie node, even if they</em>
<a name="313" href="#313">313</a> <em class="jxr_javadoccomment">   * are not on the same level.  See buildTreeRec, below.</em>
<a name="314" href="#314">314</a> <em class="jxr_javadoccomment">   *</em>
<a name="315" href="#315">315</a> <em class="jxr_javadoccomment">   */</em>  
<a name="316" href="#316">316</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">CarriedTrieNodeRef</a>
<a name="317" href="#317">317</a>   {
<a name="318" href="#318">318</a>       <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a>   content;
<a name="319" href="#319">319</a>       
<a name="320" href="#320">320</a>       <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">CarriedTrieNodeRef</a>() {
<a name="321" href="#321">321</a>           content = <strong class="jxr_keyword">null</strong>;
<a name="322" href="#322">322</a>       }
<a name="323" href="#323">323</a>   }
<a name="324" href="#324">324</a> 
<a name="325" href="#325">325</a>   
<a name="326" href="#326">326</a>   <em class="jxr_javadoccomment">/**</em>
<a name="327" href="#327">327</a> <em class="jxr_javadoccomment">   * Given a sorted set of cut points, build a trie that will find the correct</em>
<a name="328" href="#328">328</a> <em class="jxr_javadoccomment">   * partition quickly.</em>
<a name="329" href="#329">329</a> <em class="jxr_javadoccomment">   * @param splits the list of cut points</em>
<a name="330" href="#330">330</a> <em class="jxr_javadoccomment">   * @param lower the lower bound of partitions 0..numPartitions-1</em>
<a name="331" href="#331">331</a> <em class="jxr_javadoccomment">   * @param upper the upper bound of partitions 0..numPartitions-1</em>
<a name="332" href="#332">332</a> <em class="jxr_javadoccomment">   * @param prefix the prefix that we have already checked against</em>
<a name="333" href="#333">333</a> <em class="jxr_javadoccomment">   * @param maxDepth the maximum depth we will build a trie for</em>
<a name="334" href="#334">334</a> <em class="jxr_javadoccomment">   * @return the trie node that will divide the splits correctly</em>
<a name="335" href="#335">335</a> <em class="jxr_javadoccomment">   */</em>
<a name="336" href="#336">336</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> buildTrie(BinaryComparable[] splits, <strong class="jxr_keyword">int</strong> lower,
<a name="337" href="#337">337</a>           <strong class="jxr_keyword">int</strong> upper, byte[] prefix, <strong class="jxr_keyword">int</strong> maxDepth) {
<a name="338" href="#338">338</a>       <strong class="jxr_keyword">return</strong> buildTrieRec
<a name="339" href="#339">339</a>                (splits, lower, upper, prefix, maxDepth, <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">CarriedTrieNodeRef</a>());
<a name="340" href="#340">340</a>   }
<a name="341" href="#341">341</a>   
<a name="342" href="#342">342</a>   <em class="jxr_javadoccomment">/**</em>
<a name="343" href="#343">343</a> <em class="jxr_javadoccomment">   * This is the core of buildTrie.  The interface, and stub, above, just adds</em>
<a name="344" href="#344">344</a> <em class="jxr_javadoccomment">   * an empty CarriedTrieNodeRef.  </em>
<a name="345" href="#345">345</a> <em class="jxr_javadoccomment">   * </em>
<a name="346" href="#346">346</a> <em class="jxr_javadoccomment">   * We build trie nodes in depth first order, which is also in key space</em>
<a name="347" href="#347">347</a> <em class="jxr_javadoccomment">   * order.  Every leaf node is referenced as a slot in a parent internal</em>
<a name="348" href="#348">348</a> <em class="jxr_javadoccomment">   * node.  If two adjacent slots [in the DFO] hold leaf nodes that have</em>
<a name="349" href="#349">349</a> <em class="jxr_javadoccomment">   * no split point, then they are not separated by a split point either, </em>
<a name="350" href="#350">350</a> <em class="jxr_javadoccomment">   * because there's no place in key space for that split point to exist.</em>
<a name="351" href="#351">351</a> <em class="jxr_javadoccomment">   * </em>
<a name="352" href="#352">352</a> <em class="jxr_javadoccomment">   * When that happens, the leaf nodes would be semantically identical, and</em>
<a name="353" href="#353">353</a> <em class="jxr_javadoccomment">   * we reuse the object.  A single CarriedTrieNodeRef "ref" lives for the </em>
<a name="354" href="#354">354</a> <em class="jxr_javadoccomment">   * duration of the tree-walk.  ref carries a potentially reusable, unsplit</em>
<a name="355" href="#355">355</a> <em class="jxr_javadoccomment">   * leaf node for such reuse until a leaf node with a split arises, which </em>
<a name="356" href="#356">356</a> <em class="jxr_javadoccomment">   * breaks the chain until we need to make a new unsplit leaf node.</em>
<a name="357" href="#357">357</a> <em class="jxr_javadoccomment">   * </em>
<a name="358" href="#358">358</a> <em class="jxr_javadoccomment">   * Note that this use of CarriedTrieNodeRef means that for internal nodes, </em>
<a name="359" href="#359">359</a> <em class="jxr_javadoccomment">   * for internal nodes if this code is modified in any way we still need </em>
<a name="360" href="#360">360</a> <em class="jxr_javadoccomment">   * to make or fill in the subnodes in key space order.</em>
<a name="361" href="#361">361</a> <em class="jxr_javadoccomment">   */</em>
<a name="362" href="#362">362</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a> buildTrieRec(BinaryComparable[] splits, <strong class="jxr_keyword">int</strong> lower,
<a name="363" href="#363">363</a>       <strong class="jxr_keyword">int</strong> upper, byte[] prefix, <strong class="jxr_keyword">int</strong> maxDepth, <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">CarriedTrieNodeRef</a> ref) {
<a name="364" href="#364">364</a>     <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> depth = prefix.length;
<a name="365" href="#365">365</a>     <em class="jxr_comment">// We generate leaves for a single split point as well as for </em>
<a name="366" href="#366">366</a>     <em class="jxr_comment">// no split points.</em>
<a name="367" href="#367">367</a>     <strong class="jxr_keyword">if</strong> (depth &gt;= maxDepth || lower &gt;= upper - 1) {
<a name="368" href="#368">368</a>         <em class="jxr_comment">// If we have two consecutive requests for an unsplit trie node, we</em>
<a name="369" href="#369">369</a>         <em class="jxr_comment">// can deliver the same one the second time.</em>
<a name="370" href="#370">370</a>         <strong class="jxr_keyword">if</strong> (lower == upper &amp;&amp; ref.content != <strong class="jxr_keyword">null</strong>) {
<a name="371" href="#371">371</a>             <strong class="jxr_keyword">return</strong> ref.content;
<a name="372" href="#372">372</a>         }
<a name="373" href="#373">373</a>         <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">TrieNode</a>  result = LeafTrieNodeFactory(depth, splits, lower, upper);
<a name="374" href="#374">374</a>         ref.content = lower == upper ? result : <strong class="jxr_keyword">null</strong>;
<a name="375" href="#375">375</a>         <strong class="jxr_keyword">return</strong> result;
<a name="376" href="#376">376</a>     }
<a name="377" href="#377">377</a>     <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">InnerTrieNode</a> result = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/mapreduce/hadoopbackport/TotalOrderPartitioner.html">InnerTrieNode</a>(depth);
<a name="378" href="#378">378</a>     byte[] trial = Arrays.copyOf(prefix, prefix.length + 1);
<a name="379" href="#379">379</a>     <em class="jxr_comment">// append an extra byte on to the prefix</em>
<a name="380" href="#380">380</a>     <strong class="jxr_keyword">int</strong>         currentBound = lower;
<a name="381" href="#381">381</a>     <strong class="jxr_keyword">for</strong>(<strong class="jxr_keyword">int</strong> ch = 0; ch &lt; 0xFF; ++ch) {
<a name="382" href="#382">382</a>       trial[depth] = (byte) (ch + 1);
<a name="383" href="#383">383</a>       lower = currentBound;
<a name="384" href="#384">384</a>       <strong class="jxr_keyword">while</strong> (currentBound &lt; upper) {
<a name="385" href="#385">385</a>         <strong class="jxr_keyword">if</strong> (splits[currentBound].compareTo(trial, 0, trial.length) &gt;= 0) {
<a name="386" href="#386">386</a>           <strong class="jxr_keyword">break</strong>;
<a name="387" href="#387">387</a>         }
<a name="388" href="#388">388</a>         currentBound += 1;
<a name="389" href="#389">389</a>       }
<a name="390" href="#390">390</a>       trial[depth] = (byte) ch;
<a name="391" href="#391">391</a>       result.child[0xFF &amp; ch]
<a name="392" href="#392">392</a>                    = buildTrieRec(splits, lower, currentBound, trial, maxDepth, ref);
<a name="393" href="#393">393</a>     }
<a name="394" href="#394">394</a>     <em class="jxr_comment">// pick up the rest</em>
<a name="395" href="#395">395</a>     trial[depth] = (byte)0xFF;
<a name="396" href="#396">396</a>     result.child[0xFF] 
<a name="397" href="#397">397</a>                  = buildTrieRec(splits, lower, currentBound, trial, maxDepth, ref);
<a name="398" href="#398">398</a>     
<a name="399" href="#399">399</a>     <strong class="jxr_keyword">return</strong> result;
<a name="400" href="#400">400</a>   }
<a name="401" href="#401">401</a> }
</pre>
<hr/><div id="footer">This page was automatically generated by <a href="http://maven.apache.org/">Maven</a></div></body>
</html>

