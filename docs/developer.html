<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>Chapter&nbsp;1.&nbsp;Building and Developing Apache HBase (TM)</title><link rel="stylesheet" type="text/css" href="css/freebsd_docbook.css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.76.1"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="chapter" title="Chapter&nbsp;1.&nbsp;Building and Developing Apache HBase (TM)"><div class="titlepage"><div><div><h2 class="title"><a name="developer"></a>Chapter&nbsp;1.&nbsp;Building and Developing Apache HBase (TM)</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#repos">1.1. Apache HBase Repositories</a></span></dt><dd><dl><dt><span class="section"><a href="#svn">1.1.1. SVN</a></span></dt><dt><span class="section"><a href="#git">1.1.2. Git</a></span></dt></dl></dd><dt><span class="section"><a href="#ides">1.2. IDEs</a></span></dt><dd><dl><dt><span class="section"><a href="#eclipse">1.2.1. Eclipse</a></span></dt></dl></dd><dt><span class="section"><a href="#build">1.3. Building Apache HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#build.basic">1.3.1. Basic Compile</a></span></dt><dt><span class="section"><a href="#build.snappy">1.3.2. Building in snappy compression support</a></span></dt><dt><span class="section"><a href="#build.tgz">1.3.3. Building the HBase tarball</a></span></dt><dt><span class="section"><a href="#build.gotchas">1.3.4. Build Gotchas</a></span></dt></dl></dd><dt><span class="section"><a href="#mvn_repo">1.4. Adding an Apache HBase release to Apache's Maven Repository</a></span></dt><dt><span class="section"><a href="#documentation">1.5. Generating the HBase Reference Guide</a></span></dt><dt><span class="section"><a href="#hbase.org">1.6. Updating hbase.apache.org</a></span></dt><dd><dl><dt><span class="section"><a href="#hbase.org.site.contributing">1.6.1. Contributing to hbase.apache.org</a></span></dt><dt><span class="section"><a href="#hbase.org.site.publishing">1.6.2. Publishing hbase.apache.org</a></span></dt></dl></dd><dt><span class="section"><a href="#hbase.tests">1.7. Tests</a></span></dt><dd><dl><dt><span class="section"><a href="#hbase.moduletests">1.7.1. Apache HBase Modules</a></span></dt><dt><span class="section"><a href="#hbase.unittests">1.7.2. Unit Tests</a></span></dt><dt><span class="section"><a href="#hbase.unittests.cmds">1.7.3. Running tests</a></span></dt><dt><span class="section"><a href="#hbase.tests.writing">1.7.4. Writing Tests</a></span></dt><dt><span class="section"><a href="#integration.tests">1.7.5. Integration Tests</a></span></dt></dl></dd><dt><span class="section"><a href="#maven.build.commands">1.8. Maven Build Commands</a></span></dt><dd><dl><dt><span class="section"><a href="#maven.build.commands.compile">1.8.1. Compile</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unitall">1.8.2. Running all or individual Unit Tests</a></span></dt><dt><span class="section"><a href="#maven.build.hadoop">1.8.3. Building against various hadoop versions.</a></span></dt></dl></dd><dt><span class="section"><a href="#getting.involved">1.9. Getting Involved</a></span></dt><dd><dl><dt><span class="section"><a href="#mailing.list">1.9.1. Mailing Lists</a></span></dt><dt><span class="section"><a href="#jira">1.9.2. Jira</a></span></dt></dl></dd><dt><span class="section"><a href="#developing">1.10. Developing</a></span></dt><dd><dl><dt><span class="section"><a href="#codelines">1.10.1. Codelines</a></span></dt><dt><span class="section"><a href="#unit.tests">1.10.2. Unit Tests</a></span></dt><dt><span class="section"><a href="#code.standards">1.10.3. Code Standards</a></span></dt><dt><span class="section"><a href="#design.invariants">1.10.4. Invariants</a></span></dt><dt><span class="section"><a href="#run.insitu">1.10.5. Running In-Situ</a></span></dt></dl></dd><dt><span class="section"><a href="#submitting.patches">1.11. Submitting Patches</a></span></dt><dd><dl><dt><span class="section"><a href="#submitting.patches.create">1.11.1. Create Patch</a></span></dt><dt><span class="section"><a href="#submitting.patches.naming">1.11.2. Patch File Naming</a></span></dt><dt><span class="section"><a href="#submitting.patches.tests">1.11.3. Unit Tests</a></span></dt><dt><span class="section"><a href="#submitting.patches.jira">1.11.4. Attach Patch to Jira</a></span></dt><dt><span class="section"><a href="#common.patch.feedback">1.11.5. Common Patch Feedback</a></span></dt><dt><span class="section"><a href="#reviewboard">1.11.6. ReviewBoard</a></span></dt><dt><span class="section"><a href="#committing.patches">1.11.7. Committing Patches</a></span></dt></dl></dd></dl></div><p>This chapter will be of interest only to those building and developing Apache HBase (TM) (i.e., as opposed to
    just downloading the latest distribution).
    </p><div class="section" title="1.1.&nbsp;Apache HBase Repositories"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="repos"></a>1.1.&nbsp;Apache HBase Repositories</h2></div></div></div><p>There are two different repositories for Apache HBase: Subversion (SVN) and Git. The former is the system of record for committers, but the latter is easier to work with to build and contribute. SVN updates get automatically propagated to the Git repo.</p><div class="section" title="1.1.1.&nbsp;SVN"><div class="titlepage"><div><div><h3 class="title"><a name="svn"></a>1.1.1.&nbsp;SVN</h3></div></div></div><pre class="programlisting">
svn co http://svn.apache.org/repos/asf/hbase/trunk hbase-core-trunk
        </pre></div><div class="section" title="1.1.2.&nbsp;Git"><div class="titlepage"><div><div><h3 class="title"><a name="git"></a>1.1.2.&nbsp;Git</h3></div></div></div><pre class="programlisting">
git clone git://git.apache.org/hbase.git
        </pre></div></div><div class="section" title="1.2.&nbsp;IDEs"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ides"></a>1.2.&nbsp;IDEs</h2></div></div></div><div class="section" title="1.2.1.&nbsp;Eclipse"><div class="titlepage"><div><div><h3 class="title"><a name="eclipse"></a>1.2.1.&nbsp;Eclipse</h3></div></div></div><div class="section" title="1.2.1.1.&nbsp;Code Formatting"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.code.formatting"></a>1.2.1.1.&nbsp;Code Formatting</h4></div></div></div><p>Under the <code class="filename">dev-support</code> folder, you will find <code class="filename">hbase_eclipse_formatter.xml</code>.
            We encourage you to have this formatter in place in eclipse when editing HBase code.  To load it into eclipse:
</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Go to Eclipse-&gt;Preferences...</p></li><li class="listitem"><p>In Preferences, Go to Java-&gt;Code Style-&gt;Formatter</p></li><li class="listitem"><p>Import... <code class="filename">hbase_eclipse_formatter.xml</code></p></li><li class="listitem"><p>Click Apply</p></li><li class="listitem"><p>Still in Preferences, Go to Java-&gt;Editor-&gt;Save Actions</p></li><li class="listitem"><p>Check the following:
</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Perform the selected actions on save</p></li><li class="listitem"><p>Format source code</p></li><li class="listitem"><p>Format edited lines</p></li></ol></div><p>
</p></li><li class="listitem"><p>Click Apply</p></li></ol></div><p>
</p><p>In addition to the automatic formatting, make sure you follow the style guidelines explained in <a class="xref" href="#common.patch.feedback" title="1.11.5.&nbsp;Common Patch Feedback">Section&nbsp;1.11.5, &#8220;Common Patch Feedback&#8221;</a></p><p>Also, no @author tags - that's a rule.  Quality Javadoc comments are appreciated.  And include the Apache license.</p></div><div class="section" title="1.2.1.2.&nbsp;Subversive Plugin"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.svn"></a>1.2.1.2.&nbsp;Subversive Plugin</h4></div></div></div><p>Download and install the Subversive plugin.</p><p>Set up an SVN Repository target from <a class="xref" href="#svn" title="1.1.1.&nbsp;SVN">Section&nbsp;1.1.1, &#8220;SVN&#8221;</a>, then check out the code.</p></div><div class="section" title="1.2.1.3.&nbsp;Git Plugin"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.git.plugin"></a>1.2.1.3.&nbsp;Git Plugin</h4></div></div></div><p>If you cloned the project via git, download and install the Git plugin (EGit). Attach to your local git repo (via the Git Repositories window) and you'll be able to see file revision history, generate patches, etc.</p></div><div class="section" title="1.2.1.4.&nbsp;HBase Project Setup in Eclipse"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.maven.setup"></a>1.2.1.4.&nbsp;HBase Project Setup in Eclipse</h4></div></div></div><p>The easiest way is to use the m2eclipse plugin for Eclipse. Eclipse Indigo or newer has m2eclipse built-in, or it can be found here:http://www.eclipse.org/m2e/. M2Eclipse provides Maven integration for Eclipse - it even lets you use the direct Maven commands from within Eclipse to compile and test your project.</p><p>To import the project, you merely need to go to File-&gt;Import...Maven-&gt;Existing Maven Projects and then point Eclipse at the HBase root directory; m2eclipse will automatically find all the hbase modules for you.</p><p>If you install m2eclipse and import HBase in your workspace, you will have to fix your eclipse Build Path.
            Remove <code class="filename">target</code> folder, add <code class="filename">target/generated-jamon</code>
            and <code class="filename">target/generated-sources/java</code> folders. You may also remove from your Build Path
            the exclusions on the <code class="filename">src/main/resources</code> and <code class="filename">src/test/resources</code>
            to avoid error message in the console 'Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (default) on project hbase:
            'An Ant BuildException has occured: Replace: source file .../target/classes/hbase-default.xml doesn't exist'. This will also
            reduce the eclipse build cycles and make your life easier when developing.</p></div><div class="section" title="1.2.1.5.&nbsp;Import into eclipse with the command line"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.commandline"></a>1.2.1.5.&nbsp;Import into eclipse with the command line</h4></div></div></div><p>For those not inclined to use m2eclipse, you can generate the Eclipse files from the command line. First, run (you should only have to do this once):
            </p><pre class="programlisting">mvn clean install -DskipTests</pre><p>
            and then close Eclipse and execute...
            </p><pre class="programlisting">mvn eclipse:eclipse</pre><p>
            ... from your local HBase project directory in your workspace to generate some new <code class="filename">.project</code>
            and <code class="filename">.classpath</code>files.  Then reopen Eclipse, or refresh your eclipse project (F5), and import
            the .project file in the HBase directory to a workspace.
            </p></div><div class="section" title="1.2.1.6.&nbsp;Maven Classpath Variable"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.maven.class"></a>1.2.1.6.&nbsp;Maven Classpath Variable</h4></div></div></div><p>The <code class="varname">M2_REPO</code> classpath variable needs to be set up for the project.  This needs to be set to
            your local Maven repository, which is usually <code class="filename">~/.m2/repository</code></p>
            If this classpath variable is not configured, you will see compile errors in Eclipse like this...
            <pre class="programlisting">
Description	Resource	Path	Location	Type
The project cannot be built until build path errors are resolved	hbase		Unknown	Java Problem
Unbound classpath variable: 'M2_REPO/asm/asm/3.1/asm-3.1.jar' in project 'hbase'	hbase		Build path	Build Path Problem
Unbound classpath variable: 'M2_REPO/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar' in project 'hbase'	hbase		Build path	Build Path Problem
Unbound classpath variable: 'M2_REPO/com/google/guava/guava/r09/guava-r09.jar' in project 'hbase'	hbase		Build path	Build Path Problem
Unbound classpath variable: 'M2_REPO/com/google/protobuf/protobuf-java/2.3.0/protobuf-java-2.3.0.jar' in project 'hbase'	hbase		Build path	Build Path Problem Unbound classpath variable:
            </pre></div><div class="section" title="1.2.1.7.&nbsp;Eclipse Known Issues"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.issues"></a>1.2.1.7.&nbsp;Eclipse Known Issues</h4></div></div></div><p>Eclipse will currently complain about <code class="filename">Bytes.java</code>.  It is not possible to turn these errors off.</p><pre class="programlisting">
Description	Resource	Path	Location	Type
Access restriction: The method arrayBaseOffset(Class) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1061	Java Problem
Access restriction: The method arrayIndexScale(Class) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1064	Java Problem
Access restriction: The method getLong(Object, long) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1111	Java Problem
             </pre></div><div class="section" title="1.2.1.8.&nbsp;Eclipse - More Information"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.more"></a>1.2.1.8.&nbsp;Eclipse - More Information</h4></div></div></div><p>For additional information on setting up Eclipse for HBase development on Windows, see
             <a class="link" href="http://michaelmorello.blogspot.com/2011/09/hbase-subversion-eclipse-windows.html" target="_top">Michael Morello's blog</a> on the topic.
             </p></div></div></div><div class="section" title="1.3.&nbsp;Building Apache HBase"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="build"></a>1.3.&nbsp;Building Apache HBase</h2></div></div></div><div class="section" title="1.3.1.&nbsp;Basic Compile"><div class="titlepage"><div><div><h3 class="title"><a name="build.basic"></a>1.3.1.&nbsp;Basic Compile</h3></div></div></div><p>Thanks to maven, building HBase is pretty easy. You can read about the various maven commands in <a class="xref" href="#maven.build.commands" title="1.8.&nbsp;Maven Build Commands">Section&nbsp;1.8, &#8220;Maven Build Commands&#8221;</a>, but the simplest command to compile HBase from its java source code is:
       </p><pre class="programlisting">
mvn package -DskipTests
       </pre><p>
       Or, to clean up before compiling:
       </p><pre class="programlisting">
mvn clean package -DskipTests
       </pre><p>
       With Eclipse set up as explained above in <a class="xref" href="#eclipse" title="1.2.1.&nbsp;Eclipse">Section&nbsp;1.2.1, &#8220;Eclipse&#8221;</a>, you can also simply use the build command in Eclipse. To create the full installable HBase package takes a little bit more work, so read on.
       </p></div><div class="section" title="1.3.2.&nbsp;Building in snappy compression support"><div class="titlepage"><div><div><h3 class="title"><a name="build.snappy"></a>1.3.2.&nbsp;Building in snappy compression support</h3></div></div></div><p>Pass <code class="code">-Dsnappy</code> to trigger the snappy maven profile for building
            snappy native libs into hbase.  See also <a class="xref" href="#">???</a></p></div><div class="section" title="1.3.3.&nbsp;Building the HBase tarball"><div class="titlepage"><div><div><h3 class="title"><a name="build.tgz"></a>1.3.3.&nbsp;Building the HBase tarball</h3></div></div></div><p>Do the following to build the HBase tarball.
        Passing the -Prelease will generate javadoc and run the RAT plugin to verify licenses on source.
        </p><pre class="programlisting">% MAVEN_OPTS="-Xmx2g" mvn clean site install assembly:assembly -DskipTests -Prelease</pre><p>
</p></div><div class="section" title="1.3.4.&nbsp;Build Gotchas"><div class="titlepage"><div><div><h3 class="title"><a name="build.gotchas"></a>1.3.4.&nbsp;Build Gotchas</h3></div></div></div><p>If you see <code class="code">Unable to find resource 'VM_global_library.vm'</code>, ignore it.
			Its not an error.  It is <a class="link" href="http://jira.codehaus.org/browse/MSITE-286" target="_top">officially ugly</a> though.
           </p></div></div><div class="section" title="1.4.&nbsp;Adding an Apache HBase release to Apache's Maven Repository"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="mvn_repo"></a>1.4.&nbsp;Adding an Apache HBase release to Apache's Maven Repository</h2></div></div></div><p>Follow the instructions at
        <a class="link" href="http://www.apache.org/dev/publishing-maven-artifacts.html" target="_top">Publishing Maven Artifacts</a> after
        reading the below miscellaney.
        </p><p>You must use maven 3.0.x (Check by running <span class="command"><strong>mvn -version</strong></span>).
        </p><p>Let me list out the commands I used first.  The sections that follow dig in more
        on what is going on.  In this example, we are releasing the 0.92.2 jar to the apache
        maven repository.
        </p><pre class="programlisting">
  # First make a copy of the tag we want to release; presumes the release has been tagged already
  # We do this because we need to make some commits for the mvn release plugin to work.
  853  svn copy -m "Publishing 0.92.2 to mvn"  https://svn.apache.org/repos/asf/hbase/tags/0.92.2 https://svn.apache.org/repos/asf/hbase/tags/0.92.2mvn
  857  svn checkout https://svn.apache.org/repos/asf/hbase/tags/0.92.2mvn
  858  cd 0.92.2mvn/
  # Edit the version making it release version with a '-SNAPSHOT' suffix (See below for more on this)
  860  vi pom.xml
  861  svn commit -m "Add SNAPSHOT to the version" pom.xml
  862  ~/bin/mvn/bin/mvn release:clean
  865  ~/bin/mvn/bin/mvn release:prepare
  866  # Answer questions and then ^C to kill the build after the last question. See below for more on this.
  867  vi release.properties
       # Change the references to trunk svn to be 0.92.2mvn; the release plugin presumes trunk
       # Then restart the release:prepare -- it won't ask questions
       # because the properties file exists.
  868  ~/bin/mvn/bin/mvn release:prepare
  # The apache-release profile comes from the apache parent pom and does signing of artifacts published
  869  ~/bin/mvn/bin/mvn release:perform  -Papache-release
       # When done copying up to apache staging repository,
       # browse to repository.apache.org, login and finish
       # the release as according to the above
       # "Publishing Maven Artifacts.
        </pre><p>
        </p><p>Below is more detail on the commmands listed above.</p><p>At the <span class="command"><strong>mvn release:perform</strong></span> step, before starting, if you are for example
        releasing hbase 0.92.2, you need to make sure the pom.xml version is 0.92.2-SNAPSHOT.  This needs
        to be checked in.  Since we do the maven release after actual release, I've been doing this
        checkin into a copy of the release tag rather than into the actual release tag itself (presumes the release has been properly tagged in svn).
        So, say we released hbase 0.92.2 and now we want to do the release to the maven repository, in svn, the 0.92.2
        release will be tagged 0.92.2.  Making the maven release, copy the 0.92.2 tag to 0.92.2mvn.
        Check out this tag and change the version therein and commit.
        </p><p>
            Currently, the mvn release wants to go against trunk.  I haven't figured how to tell it to do otherwise
            so I do the below hack.  The hack comprises answering the questions put to you by the mvn release plugin properly,
            then immediately control-C'ing the build after the last question asked as the build release step starts to run.
            After control-C'ing it, You'll notice a release.properties in your build dir.  Review it.
            Make sure it is using the proper branch -- it tends to use trunk rather than the 0.92.2mvn or whatever
            that you want it to use -- so hand edit the release.properties file that was put under <code class="varname">${HBASE_HOME}</code>
            by the <span class="command"><strong>release:perform</strong></span> invocation.  When done, resstart the
            <span class="command"><strong>release:perform</strong></span>.
        </p><p>Here is how I'd answer the questions at <span class="command"><strong>release:prepare</strong></span> time:
        </p><pre class="programlisting">What is the release version for "HBase"? (org.apache.hbase:hbase) 0.92.2: :
What is SCM release tag or label for "HBase"? (org.apache.hbase:hbase) hbase-0.92.2: : 0.92.2mvn
What is the new development version for "HBase"? (org.apache.hbase:hbase) 0.92.3-SNAPSHOT: :
[INFO] Transforming 'HBase'...</pre><p>
        </p><p>When you run <span class="command"><strong>release:perform</strong></span>, pass <span class="command"><strong>-Papache-release</strong></span>
        else it will not 'sign' the artifacts it uploads.
        </p><p>A strange issue I ran into was the one where the upload into the apache
        repository was being sprayed across multiple apache machines making it so I could
        not release.  See <a class="link" href="https://issues.apache.org/jira/browse/INFRA-4482" target="_top">INFRA-4482 Why is my upload to mvn spread across multiple repositories?</a>.</p><p><a name="mvn.settings.file"></a>Here is my <code class="filename">~/.m2/settings.xml</code>.
        This is read by the release plugin.  The apache-release profile will pick up your
        gpg key setup from here if you've specified it into the file.  The password
        can be maven encrypted as suggested in the "Publishing Maven Artifacts" but plain
        text password works too (just don't let anyone see your local settings.xml).
        </p><pre class="programlisting">&lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0
                      http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt;
  &lt;servers&gt;
    &lt;!- To publish a snapshot of some part of Maven --&gt;
    &lt;server&gt;
      &lt;id&gt;apache.snapshots.https&lt;/id&gt;
      &lt;username&gt;YOUR_APACHE_ID
      &lt;/username&gt;
      &lt;password&gt;YOUR_APACHE_PASSWORD
      &lt;/password&gt;
    &lt;/server&gt;
    &lt;!-- To publish a website using Maven --&gt;
    &lt;!-- To stage a release of some part of Maven --&gt;
    &lt;server&gt;
      &lt;id&gt;apache.releases.https&lt;/id&gt;
      &lt;username&gt;YOUR_APACHE_ID
      &lt;/username&gt;
      &lt;password&gt;YOUR_APACHE_PASSWORD
      &lt;/password&gt;
    &lt;/server&gt;
  &lt;/servers&gt;
  &lt;profiles&gt;
    &lt;profile&gt;
      &lt;id&gt;apache-release&lt;/id&gt;
      &lt;properties&gt;
    &lt;gpg.keyname&gt;YOUR_KEYNAME&lt;/gpg.keyname&gt;
    &lt;!--Keyname is something like this ... 00A5F21E... do gpg --list-keys to find it--&gt;
    &lt;gpg.passphrase&gt;YOUR_KEY_PASSWORD
    &lt;/gpg.passphrase&gt;
      &lt;/properties&gt;
    &lt;/profile&gt;
  &lt;/profiles&gt;
&lt;/settings&gt;
        </pre><p>
        </p><p>If you see run into the below, its because you need to edit version in the pom.xml and add
        <code class="code">-SNAPSHOT</code> to the version (and commit).
        </p><pre class="programlisting">[INFO] Scanning for projects...
[INFO] Searching repository for plugin with prefix: 'release'.
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase
[INFO]    task-segment: [release:prepare] (aggregator-style)
[INFO] ------------------------------------------------------------------------
[INFO] [release:prepare {execution: default-cli}]
[INFO] ------------------------------------------------------------------------
[ERROR] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] You don't have a SNAPSHOT project in the reactor projects list.
[INFO] ------------------------------------------------------------------------
[INFO] For more information, run Maven with the -e switch
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3 seconds
[INFO] Finished at: Sat Mar 26 18:11:07 PDT 2011
[INFO] Final Memory: 35M/423M
[INFO] -----------------------------------------------------------------------</pre><p>
        </p></div><div class="section" title="1.5.&nbsp;Generating the HBase Reference Guide"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="documentation"></a>1.5.&nbsp;Generating the HBase Reference Guide</h2></div></div></div><p>The manual is marked up using <a class="link" href="http://www.docbook.org/" target="_top">docbook</a>.
              We then use the <a class="link" href="http://code.google.com/p/docbkx-tools/" target="_top">docbkx maven plugin</a>
              to transform the markup to html.  This plugin is run when you specify the <span class="command"><strong>site</strong></span>
              goal as in when you run <span class="command"><strong>mvn site</strong></span> or you can call the plugin explicitly to
              just generate the manual by doing <span class="command"><strong>mvn docbkx:generate-html</strong></span>
              (TODO: It looks like you have to run <span class="command"><strong>mvn site</strong></span> first because docbkx wants to
              include a transformed <code class="filename">hbase-default.xml</code>.  Fix).
              When you run mvn site, we do the document generation twice, once to generate the multipage
              manual and then again for the single page manual (the single page version is easier to search).
          </p></div><div class="section" title="1.6.&nbsp;Updating hbase.apache.org"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="hbase.org"></a>1.6.&nbsp;Updating hbase.apache.org</h2></div></div></div><div class="section" title="1.6.1.&nbsp;Contributing to hbase.apache.org"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.org.site.contributing"></a>1.6.1.&nbsp;Contributing to hbase.apache.org</h3></div></div></div><p>The Apache HBase apache web site (including this reference guide) is maintained as part of the main Apache HBase source tree, under <code class="filename">/src/docbkx</code> and <code class="filename">/src/site</code>. The former is this reference guide; the latter, in most cases, are legacy pages that are in the process of being merged into the docbkx tree.</p><p>To contribute to the reference guide, edit these files and submit them as a patch (see <a class="xref" href="#submitting.patches" title="1.11.&nbsp;Submitting Patches">Section&nbsp;1.11, &#8220;Submitting Patches&#8221;</a>). Your Jira should contain a summary of the changes in each section (see <a class="link" href="https://issues.apache.org/jira/browse/HBASE-6081" target="_top">HBASE-6081</a> for an example).</p><p>To generate the site locally while you're working on it, run:
      </p><pre class="programlisting">mvn site</pre><p>
      Then you can load up the generated HTML files in your browser (file are under <code class="filename">/target/site</code>).</p></div><div class="section" title="1.6.2.&nbsp;Publishing hbase.apache.org"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.org.site.publishing"></a>1.6.2.&nbsp;Publishing hbase.apache.org</h3></div></div></div><p>As of <a class="link" href="https://issues.apache.org/jira/browse/INFRA-5680" target="_top">INFRA-5680 Migrate apache hbase website</a>,
          to publish the website, build it, and then deploy it over a checkout of <code class="filename">https://svn.apache.org/repos/asf/hbase/hbase.apache.org/trunk</code>,
          and then check it in.  For example, if trunk is checked out out at <code class="filename">/Users/stack/checkouts/trunk</code>
          and hbase.apache.org is checked out at <code class="filename">/Users/stack/checkouts/hbase.apache.org/trunk</code>, to update
          the site, do the following:
          </p><pre class="programlisting">
              # Build the site and deploy it to the checked out directory
              # Getting the javadoc into site is a little tricky.  You have to build it independent, then
              # 'aggregate' it at top-level so the pre-site site lifecycle step can find it; that is
              # what the javadoc:javadoc and javadoc:aggregate is about.
              $ MAVEN_OPTS=" -Xmx3g" mvn clean -DskipTests javadoc:javadoc javadoc:aggregate site  site:stage -DstagingDirectory=/Users/stack/checkouts/hbase.apache.org/trunk
              # Check the deployed site by viewing in a brower.
              # If all is good, commit it and it will show up at http://hbase.apache.org
              #
              $ cd /Users/stack/checkouts/hbase.apache.org/trunk
              $ svn commit -m 'Committing latest version of website...'
          </pre><p>
      </p></div></div><div class="section" title="1.7.&nbsp;Tests"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="hbase.tests"></a>1.7.&nbsp;Tests</h2></div></div></div><p> Developers, at a minimum, should familiarize themselves with the unit test detail; unit tests in
HBase have a character not usually seen in other projects.</p><div class="section" title="1.7.1.&nbsp;Apache HBase Modules"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.moduletests"></a>1.7.1.&nbsp;Apache HBase Modules</h3></div></div></div><p>As of 0.96, Apache HBase is split into multiple modules which creates "interesting" rules for
how and where tests are written. If you are writting code for <code class="classname">hbase-server</code>, see
<a class="xref" href="#hbase.unittests" title="1.7.2.&nbsp;Unit Tests">Section&nbsp;1.7.2, &#8220;Unit Tests&#8221;</a> for how to write your tests; these tests can spin
up a minicluster and will need to be categorized. For any other module, for example
<code class="classname">hbase-common</code>, the tests must be strict unit tests and just test the class
under test - no use of the HBaseTestingUtility or minicluster is allowed (or even possible
given the dependency tree).</p><div class="section" title="1.7.1.1.&nbsp;Running Tests in other Modules"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.moduletest.run"></a>1.7.1.1.&nbsp;Running Tests in other Modules</h4></div></div></div>
  If the module you are developing in has no other dependencies on other HBase modules, then
  you can cd into that module and just run:
  <pre class="programlisting">mvn test</pre>
  which will just run the tests IN THAT MODULE. If there are other dependencies on other modules,
  then you will have run the command from the ROOT HBASE DIRECTORY. This will run the tests in the other
  modules, unless you specify to skip the tests in that module. For instance, to skip the tests in the hbase-server module,
  you would run:
  <pre class="programlisting">mvn clean test -PskipServerTests</pre>
  from the top level directory to run all the tests in modules other than hbase-server. Note that you
  can specify to skip tests in multiple modules as well as just for a single module. For example, to skip
  the tests in <code class="classname">hbase-server</code> and <code class="classname">hbase-common</code>, you would run:
  <pre class="programlisting">mvn clean test -PskipServerTests -PskipCommonTests</pre><p>Also, keep in mind that if you are running tests in the <code class="classname">hbase-server</code> module you will need to
  apply the maven profiles discussed in <a class="xref" href="#hbase.unittests.cmds" title="1.7.3.&nbsp;Running tests">Section&nbsp;1.7.3, &#8220;Running tests&#8221;</a> to get the tests to run properly.</p></div></div><div class="section" title="1.7.2.&nbsp;Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.unittests"></a>1.7.2.&nbsp;Unit Tests</h3></div></div></div><p>Apache HBase unit tests are subdivided into four categories: small, medium, large, and
integration with corresponding JUnit <a class="link" href="http://www.junit.org/node/581" target="_top">categories</a>:
<code class="classname">SmallTests</code>, <code class="classname">MediumTests</code>,
<code class="classname">LargeTests</code>, <code class="classname">IntegrationTests</code>.
JUnit categories are denoted using java annotations and look like this in your unit test code.
</p><pre class="programlisting">...
@Category(SmallTests.class)
public class TestHRegionInfo {
  @Test
  public void testCreateHRegionInfoName() throws Exception {
    // ...
  }
}</pre><p>
The above example shows how to mark a unit test as belonging to the small category.
All unit tests in HBase have a categorization.
</p><p>
The first three categories, small, medium, and large are for tests run when
you type <code class="code">$ mvn test</code>; i.e. these three categorizations are for
HBase unit tests. The integration category is for not for unit tests but for integration
tests.  These are run when you invoke <code class="code">$ mvn verify</code>.  Integration tests
are described in <a class="xref" href="#integration.tests" title="1.7.5.&nbsp;Integration Tests">Section&nbsp;1.7.5, &#8220;Integration Tests&#8221;</a> and will not be discussed further
in this section on HBase unit tests.</p><p>
Apache HBase uses a patched maven surefire plugin and maven profiles to implement
its unit test characterizations.
</p><p>Read the below to figure which annotation of the set small, medium, and large to
put on your new HBase unit test.
</p><div class="section" title="1.7.2.1.&nbsp;Small Tests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.small"></a>1.7.2.1.&nbsp;Small Tests<a class="indexterm" name="d4590e445"></a></h4></div></div></div><p>
<span class="emphasis"><em>Small</em></span> tests are executed in a shared JVM. We put in this category all the tests that can
be executed quickly in a shared JVM.  The maximum execution time for a small test is 15 seconds,
and small tests should not use a (mini)cluster.</p></div><div class="section" title="1.7.2.2.&nbsp;Medium Tests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.medium"></a>1.7.2.2.&nbsp;Medium Tests<a class="indexterm" name="d4590e456"></a></h4></div></div></div><p><span class="emphasis"><em>Medium</em></span> tests represent tests that must be executed
before proposing a patch. They are designed to run in less than 30 minutes altogether,
and are quite stable in their results. They are designed to last less than 50 seconds
individually. They can use a cluster, and each of them is executed in a separate JVM.
</p></div><div class="section" title="1.7.2.3.&nbsp;Large Tests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.large"></a>1.7.2.3.&nbsp;Large Tests<a class="indexterm" name="d4590e466"></a></h4></div></div></div><p><span class="emphasis"><em>Large</em></span> tests are everything else. They are typically large-scale
tests, regression tests for specific bugs, timeout tests, performance tests.
They are executed before a commit on the pre-integration machines. They can be run on
the developer machine as well.
</p></div><div class="section" title="1.7.2.4.&nbsp;Integration Tests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.integration"></a>1.7.2.4.&nbsp;Integration Tests<a class="indexterm" name="d4590e476"></a></h4></div></div></div><p><span class="emphasis"><em>Integration</em></span> tests are system level tests. See
<a class="xref" href="#integration.tests" title="1.7.5.&nbsp;Integration Tests">Section&nbsp;1.7.5, &#8220;Integration Tests&#8221;</a> for more info.
</p></div></div><div class="section" title="1.7.3.&nbsp;Running tests"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.unittests.cmds"></a>1.7.3.&nbsp;Running tests</h3></div></div></div><p>Below we describe how to run the Apache HBase junit categories.</p><div class="section" title="1.7.3.1.&nbsp;Default: small and medium category tests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.cmds.test"></a>1.7.3.1.&nbsp;Default: small and medium category tests
</h4></div></div></div><p>Running </p><pre class="programlisting">mvn test</pre><p> will execute all small tests in a single JVM
(no fork) and then medium tests in a separate JVM for each test instance.
Medium tests are NOT executed if there is an error in a small test.
Large tests are NOT executed.  There is one report for small tests, and one report for
medium tests if they are executed.
</p></div><div class="section" title="1.7.3.2.&nbsp;Running all tests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.cmds.test.runAllTests"></a>1.7.3.2.&nbsp;Running all tests</h4></div></div></div><p>Running </p><pre class="programlisting">mvn test -P runAllTests</pre><p>
will execute small tests in a single JVM then medium and large tests in a separate JVM for each test.
Medium and large tests are NOT executed if there is an error in a small test.
Large tests are NOT executed if there is an error in a small or medium test.
There is one report for small tests, and one report for medium and large tests if they are executed.
</p></div><div class="section" title="1.7.3.3.&nbsp;Running a single test or all tests in a package"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.cmds.test.localtests.mytest"></a>1.7.3.3.&nbsp;Running a single test or all tests in a package</h4></div></div></div><p>To run an individual test, e.g. <code class="classname">MyTest</code>, do
</p><pre class="programlisting">mvn test -Dtest=MyTest</pre><p>  You can also
pass multiple, individual tests as a comma-delimited list:
</p><pre class="programlisting">mvn test -Dtest=MyTest1,MyTest2,MyTest3</pre><p>
You can also pass a package, which will run all tests under the package:
</p><pre class="programlisting">mvn test -Dtest=org.apache.hadoop.hbase.client.*</pre><p>
</p><p>
When <code class="code">-Dtest</code> is specified, <code class="code">localTests</code> profile will be used. It will use the official release
of maven surefire, rather than our custom surefire plugin, and the old connector (The HBase build uses a patched
version of the maven surefire plugin). Each junit tests is executed in a separate JVM (A fork per test class).
There is no parallelization when tests are running in this mode. You will see a new message at the end of the
-report: "[INFO] Tests are skipped". It's harmless. While you need to make sure the sum of <code class="code">Tests run:</code> in
the <code class="code">Results :</code> section of test reports matching the number of tests you specified because no
error will be reported when a non-existent test case is specified.
</p></div><div class="section" title="1.7.3.4.&nbsp;Other test invocation permutations"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.cmds.test.profiles"></a>1.7.3.4.&nbsp;Other test invocation permutations</h4></div></div></div><p>Running </p><pre class="programlisting">mvn test -P runSmallTests</pre><p> will execute "small" tests only, using a single JVM.
</p><p>Running </p><pre class="programlisting">mvn test -P runMediumTests</pre><p> will execute "medium" tests only, launching a new JVM for each test-class.
</p><p>Running </p><pre class="programlisting">mvn test -P runLargeTests</pre><p> will execute "large" tests only, launching a new JVM for each test-class.
</p><p>For convenience, you can run </p><pre class="programlisting">mvn test -P runDevTests</pre><p> to execute both small and medium tests, using a single JVM.
</p></div><div class="section" title="1.7.3.5.&nbsp;Running tests faster"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.test.faster"></a>1.7.3.5.&nbsp;Running tests faster</h4></div></div></div><p>
By default, <code class="code">$ mvn test -P runAllTests</code> runs 5 tests in parallel.
It can be increased on a developer's machine. Allowing that you can have 2
tests in parallel per core, and you need about 2Gb of memory per test (at the
extreme), if you have an 8 core, 24Gb box, you can have 16 tests in parallel.
but the memory available limits it to 12 (24/2), To run all tests with 12 tests
in parallell, do this:
<span class="command"><strong>mvn test -P runAllTests -Dsurefire.secondPartThreadCount=12</strong></span>.
To increase the speed, you can as well use a ramdisk. You will need 2Gb of memory
to run all tests. You will also need to delete the files between two test run.
The typical way to configure a ramdisk on Linux is:
</p><pre class="programlisting">$ sudo mkdir /ram2G
sudo mount -t tmpfs -o size=2048M tmpfs /ram2G</pre><p>
You can then use it to run all HBase tests with the command:
<span class="command"><strong>mvn test -P runAllTests -Dsurefire.secondPartThreadCount=12 -Dtest.build.data.basedirectory=/ram2G</strong></span>
</p></div><div class="section" title="1.7.3.6.&nbsp;hbasetests.sh"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.cmds.test.hbasetests"></a>1.7.3.6.&nbsp;<span class="command"><strong>hbasetests.sh</strong></span></h4></div></div></div><p>It's also possible to use the script <span class="command"><strong>hbasetests.sh</strong></span>. This script runs the medium and
large tests in parallel with two maven instances, and provides a single report.  This script does not use
the hbase version of surefire so no parallelization is being done other than the two maven instances the
script sets up.
It must be executed from the directory which contains the <code class="filename">pom.xml</code>.</p><p>For example running
</p><pre class="programlisting">./dev-support/hbasetests.sh</pre><p> will execute small and medium tests.
Running </p><pre class="programlisting">./dev-support/hbasetests.sh runAllTests</pre><p> will execute all tests.
Running </p><pre class="programlisting">./dev-support/hbasetests.sh replayFailed</pre><p> will rerun the failed tests a
second time, in a separate jvm and without parallelisation.
</p></div><div class="section" title="1.7.3.7.&nbsp;Test Resource Checker"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.unittests.resource.checker"></a>1.7.3.7.&nbsp;Test Resource Checker<a class="indexterm" name="d4590e604"></a></h4></div></div></div><p>
A custom Maven SureFire plugin listener checks a  number of resources before
and after each HBase unit test runs and logs its findings at the end of the test
output files which can be found in <code class="filename">target/surefire-reports</code>
per Maven module (Tests write test reports named for the test class into this directory.
Check the <code class="filename">*-out.txt</code> files).  The resources counted are the number
of threads, the number of file descriptors, etc. If the number has increased, it adds
a <span class="emphasis"><em>LEAK?</em></span> comment in the logs. As you can have an HBase instance
running in the background, some threads can be deleted/created without any specific
action in the test. However, if the test does not work as expected, or if the test
should not impact these resources, it's worth checking these log lines
<code class="computeroutput">...hbase.ResourceChecker(157): before...</code> and
<code class="computeroutput">...hbase.ResourceChecker(157): after...</code>. For example:
<code class="computeroutput">
2012-09-26 09:22:15,315 INFO  [pool-1-thread-1] hbase.ResourceChecker(157): after: regionserver.TestColumnSeeking#testReseeking Thread=65 (was 65), OpenFileDescriptor=107 (was 107), MaxFileDescriptor=10240 (was 10240), ConnectionCount=1 (was 1)
</code>
</p></div></div><div class="section" title="1.7.4.&nbsp;Writing Tests"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.tests.writing"></a>1.7.4.&nbsp;Writing Tests</h3></div></div></div><div class="section" title="1.7.4.1.&nbsp;General rules"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.tests.rules"></a>1.7.4.1.&nbsp;General rules</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
As much as possible, tests should be written as category small tests.
</li><li class="listitem">
All tests must be written to support parallel execution on the same machine, hence they should not use shared resources as fixed ports or fixed file names.
</li><li class="listitem">
Tests should not overlog. More than 100 lines/second makes the logs complex to read and use i/o that are hence not available for the other tests.
</li><li class="listitem">
Tests can be written with <code class="classname">HBaseTestingUtility</code>.
This class offers helper functions to create a temp directory and do the cleanup, or to start a cluster.
</li></ul></div></div><div class="section" title="1.7.4.2.&nbsp;Categories and execution time"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.tests.categories"></a>1.7.4.2.&nbsp;Categories and execution time</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
All tests must be categorized, if not they could be skipped.
</li><li class="listitem">
All tests should be written to be as fast as possible.
</li><li class="listitem">
Small category tests should last less than 15 seconds, and must not have any side effect.
</li><li class="listitem">
Medium category tests should last less than 50 seconds.
</li><li class="listitem">
Large category tests should last less than 3 minutes.  This should ensure a good parallelization for people using it, and ease the analysis when the test fails.
</li></ul></div></div><div class="section" title="1.7.4.3.&nbsp;Sleeps in tests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.tests.sleeps"></a>1.7.4.3.&nbsp;Sleeps in tests</h4></div></div></div><p>Whenever possible, tests should not use <code class="methodname">Thread.sleep</code>, but rather waiting for the real event they need. This is faster and clearer for the reader.
Tests should not do a <code class="methodname">Thread.sleep</code> without testing an ending condition. This allows understanding what the test is waiting for. Moreover, the test will work whatever the machine performance is.
Sleep should be minimal to be as fast as possible. Waiting for a variable should be done in a 40ms sleep loop. Waiting for a socket operation should be done in a 200 ms sleep loop.
</p></div><div class="section" title="1.7.4.4.&nbsp;Tests using a cluster"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.tests.cluster"></a>1.7.4.4.&nbsp;Tests using a cluster
</h4></div></div></div><p>Tests using a HRegion do not have to start a cluster: A region can use the local file system.
Start/stopping a cluster cost around 10 seconds. They should not be started per test method but per test class.
Started cluster must be shutdown using <code class="methodname">HBaseTestingUtility#shutdownMiniCluster</code>, which cleans the directories.
As most as possible, tests should use the default settings for the cluster. When they don't, they should document it. This will allow to share the cluster later.
</p></div></div><div class="section" title="1.7.5.&nbsp;Integration Tests"><div class="titlepage"><div><div><h3 class="title"><a name="integration.tests"></a>1.7.5.&nbsp;Integration Tests</h3></div></div></div><p>HBase integration/system tests are tests that are beyond HBase unit tests.  They
are generally long-lasting, sizeable (the test can be asked to 1M rows or 1B rows),
targetable (they can take configuration that will point them at the ready-made cluster
they are to run against; integration tests do not include cluster start/stop code),
and verifying success, integration tests rely on public APIs only; they do not
attempt to examine server internals asserting success/fail. Integration tests
are what you would run when you need to more elaborate proofing of a release candidate
beyond what unit tests can do. They are not generally run on the Apache Continuous Integration
build server, however, some sites opt to run integration tests as a part of their
continuous testing on an actual cluster.
</p><p>
Integration tests currently live under the <code class="filename">src/test</code> directory
in the hbase-it submodule and will match the regex: <code class="filename">**/IntegrationTest*.java</code>.
All integration tests are also annotated with <code class="code">@Category(IntegrationTests.class)</code>.
</p><p>
Integration tests can be run in two modes: using a mini cluster, or against an actual distributed cluster.
Maven failsafe is used to run the tests using the mini cluster. IntegrationTestsDriver class is used for
executing the tests against a distributed cluster. Integration tests SHOULD NOT assume that they are running against a
mini cluster, and SHOULD NOT use private API's to access cluster state. To interact with the distributed or mini
cluster uniformly, <code class="code">IntegrationTestingUtility</code>, and <code class="code">HBaseCluster</code> classes,
and public client API's can be used.
</p><p>
On a distributed cluster, integration tests that use ChaosMonkey or otherwise manipulate services thru cluster manager (e.g. restart regionservers) use SSH to do it.
To run these, test process should be able to run commands on remote end, so ssh should be configured accordingly (for example, if HBase runs under hbase
user in your cluster, you can set up passwordless ssh for that user and run the test also under it). To facilitate that, <code class="code">hbase.it.clustermanager.ssh.user</code>, 
<code class="code">hbase.it.clustermanager.ssh.opts</code> and <code class="code">hbase.it.clustermanager.ssh.cmd</code> configuration settings can be used. "User" is the remote user that cluster manager should use to perform ssh commands.
"Opts" contains additional options that are passed to SSH (for example, "-i /tmp/my-key"). 
Finally, if you have some custom environment setup, "cmd" is the override format for the entire tunnel (ssh) command. The default string is {<code class="code">/usr/bin/ssh %1$s %2$s%3$s%4$s "%5$s"</code>} and is a good starting point. This is a standard Java format string with 5 arguments that is used to execute the remote command. The argument 1 (%1$s) is SSH options set the via opts setting or via environment variable, 2 is SSH user name, 3 is "@" if username is set or "" otherwise, 4 is the target host name, and 5 is the logical command to execute (that may include single quotes, so don't use them). For example, if you run the tests under non-hbase user and want to ssh as that user and change to hbase on remote machine, you can use {<code class="code">/usr/bin/ssh %1$s %2$s%3$s%4$s "su hbase - -c \"%5$s\""</code>}. That way, to kill RS (for example) integration tests may run {<code class="code">/usr/bin/ssh some-hostname "su hbase - -c \"ps aux | ... | kill ...\""</code>}.
The command is logged in the test logs, so you can verify it is correct for your environment.
</p><div class="section" title="1.7.5.1.&nbsp;Running integration tests against mini cluster"><div class="titlepage"><div><div><h4 class="title"><a name="maven.build.commands.integration.tests.mini"></a>1.7.5.1.&nbsp;Running integration tests against mini cluster</h4></div></div></div><p>HBase 0.92 added a <code class="varname">verify</code> maven target.
Invoking it, for example by doing <code class="code">mvn verify</code>, will
run all the phases up to and including the verify phase via the
maven <a class="link" href="http://maven.apache.org/plugins/maven-failsafe-plugin/" target="_top">failsafe plugin</a>,
running all the above mentioned HBase unit tests as well as tests that are in the HBase integration test group.
After you have completed
          </p><pre class="programlisting">mvn install -DskipTests</pre><p>
You can run just the integration tests by invoking:
          </p><pre class="programlisting">
cd hbase-it
mvn verify</pre><p>

If you just want to run the integration tests in top-level, you need to run two commands. First:
          </p><pre class="programlisting">mvn failsafe:integration-test</pre><p>
This actually runs ALL the integration tests.
          </p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>This command will always output <code class="code">BUILD SUCCESS</code> even if there are test failures.
          </p></div><p>
          At this point, you could grep the output by hand looking for failed tests. However, maven will do this for us; just use:
          </p><pre class="programlisting">mvn failsafe:verify</pre><p>
          The above command basically looks at all the test results (so don't remove the 'target' directory) for test failures and reports the results.</p><div class="section" title="1.7.5.1.1.&nbsp;Running a subset of Integration tests"><div class="titlepage"><div><div><h5 class="title"><a name="maven.build.commanas.integration.tests2"></a>1.7.5.1.1.&nbsp;Running a subset of Integration tests</h5></div></div></div><p>This is very similar to how you specify running a subset of unit tests (see above), but use the property
	      <code class="code">it.test</code> instead of <code class="code">test</code>.
To just run <code class="classname">IntegrationTestClassXYZ.java</code>, use:
          </p><pre class="programlisting">mvn failsafe:integration-test -Dit.test=IntegrationTestClassXYZ</pre><p>
          The next thing you might want to do is run groups of integration tests, say all integration tests that are named IntegrationTestClassX*.java:
          </p><pre class="programlisting">mvn failsafe:integration-test -Dit.test=*ClassX*</pre><p>
          This runs everything that is an integration test that matches *ClassX*. This means anything matching: "**/IntegrationTest*ClassX*".
          You can also run multiple groups of integration tests using comma-delimited lists (similar to unit tests). Using a list of matches still supports full regex matching for each of the groups.This would look something like:
          </p><pre class="programlisting">mvn failsafe:integration-test -Dit.test=*ClassX*, *ClassY</pre><p>
          </p></div></div><div class="section" title="1.7.5.2.&nbsp;Running integration tests against distributed cluster"><div class="titlepage"><div><div><h4 class="title"><a name="maven.build.commands.integration.tests.distributed"></a>1.7.5.2.&nbsp;Running integration tests against distributed cluster</h4></div></div></div><p>
If you have an already-setup HBase cluster, you can launch the integration tests by invoking the class <code class="code">IntegrationTestsDriver</code>. You may have to
run test-compile first. The configuration will be picked by the bin/hbase script.
</p><pre class="programlisting">mvn test-compile</pre><p>
Then launch the tests with:
</p><pre class="programlisting">bin/hbase [--config config_dir] org.apache.hadoop.hbase.IntegrationTestsDriver [-test=class_regex]</pre><p>

This execution will launch the tests under <code class="code">hbase-it/src/test</code>, having <code class="code">@Category(IntegrationTests.class)</code> annotation,
and a name starting with <code class="code">IntegrationTests</code>. If specified, class_regex will be   used to filter test classes. The regex is checked against full class name; so, part of class name can be used.
IntegrationTestsDriver uses Junit to run the tests. Currently there is no support for running integration tests against a distributed cluster using maven (see <a class="link" href="https://issues.apache.org/jira/browse/HBASE-6201" target="_top">HBASE-6201</a>).
</p><p>
The tests interact with the distributed cluster by using the methods in the <code class="code">DistributedHBaseCluster</code> (implementing <code class="code">HBaseCluster</code>) class, which in turn uses a pluggable <code class="code">ClusterManager</code>. Concrete implementations provide actual functionality for carrying out deployment-specific and environment-dependent tasks (SSH, etc). The default <code class="code">ClusterManager</code> is <code class="code">HBaseClusterManager</code>, which uses SSH to remotely execute start/stop/kill/signal commands, and assumes some posix commands (ps, etc). Also assumes the user running the test has enough "power" to start/stop servers on the remote machines. By default, it picks up <code class="code">HBASE_SSH_OPTS, HBASE_HOME, HBASE_CONF_DIR</code> from the env, and uses <code class="code">bin/hbase-daemon.sh</code> to carry out the actions. Currently tarball deployments, deployments which uses hbase-daemons.sh, and <a class="link" href="http://incubator.apache.org/ambari/" target="_top">Apache Ambari</a> deployments are supported. /etc/init.d/ scripts are not supported for now, but it can be easily added. For other deployment options, a ClusterManager can be implemented and plugged in.
</p></div><div class="section" title="1.7.5.3.&nbsp;Destructive integration / system tests"><div class="titlepage"><div><div><h4 class="title"><a name="maven.build.commands.integration.tests.destructive"></a>1.7.5.3.&nbsp;Destructive integration / system tests</h4></div></div></div><p>
	In 0.96, a tool named <code class="code">ChaosMonkey</code> has been introduced. It is modeled after the <a class="link" href="http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html" target="_top">same-named tool by Netflix</a>.
Some of the tests use ChaosMonkey to simulate faults in the running cluster in the way of killing random servers,
disconnecting servers, etc. ChaosMonkey can also be used as a stand-alone tool to run a (misbehaving) policy while you
are running other tests.
</p><p>
ChaosMonkey defines Action's and Policy's. Actions are sequences of events. We have at least the following actions:
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Restart active master (sleep 5 sec)</li><li class="listitem">Restart random regionserver (sleep 5 sec)</li><li class="listitem">Restart random regionserver (sleep 60 sec)</li><li class="listitem">Restart META regionserver (sleep 5 sec)</li><li class="listitem">Restart ROOT regionserver (sleep 5 sec)</li><li class="listitem">Batch restart of 50% of regionservers (sleep 5 sec)</li><li class="listitem">Rolling restart of 100% of regionservers (sleep 5 sec)</li></ul></div><p>

Policies on the other hand are responsible for executing the actions based on a strategy.
The default policy is to execute a random action every minute based on predefined action
weights. ChaosMonkey executes predefined named policies until it is stopped. More than one
policy can be active at any time.
</p><p>
  To run ChaosMonkey as a standalone tool deploy your HBase cluster as usual. ChaosMonkey uses the configuration
from the bin/hbase script, thus no extra configuration needs to be done. You can invoke the ChaosMonkey by running:
</p><pre class="programlisting">bin/hbase org.apache.hadoop.hbase.util.ChaosMonkey</pre><p>

This will output smt like:
</p><pre class="programlisting">
12/11/19 23:21:57 INFO util.ChaosMonkey: Using ChaosMonkey Policy: class org.apache.hadoop.hbase.util.ChaosMonkey$PeriodicRandomActionPolicy, period:60000
12/11/19 23:21:57 INFO util.ChaosMonkey: Sleeping for 26953 to add jitter
12/11/19 23:22:24 INFO util.ChaosMonkey: Performing action: Restart active master
12/11/19 23:22:24 INFO util.ChaosMonkey: Killing master:master.example.com,60000,1353367210440
12/11/19 23:22:24 INFO hbase.HBaseCluster: Aborting Master: master.example.com,60000,1353367210440
12/11/19 23:22:24 INFO hbase.ClusterManager: Executing remote command: ps aux | grep master | grep -v grep | tr -s ' ' | cut -d ' ' -f2 | xargs kill -s SIGKILL , hostname:master.example.com
12/11/19 23:22:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:22:25 INFO hbase.HBaseCluster: Waiting service:master to stop: master.example.com,60000,1353367210440
12/11/19 23:22:25 INFO hbase.ClusterManager: Executing remote command: ps aux | grep master | grep -v grep | tr -s ' ' | cut -d ' ' -f2 , hostname:master.example.com
12/11/19 23:22:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:22:25 INFO util.ChaosMonkey: Killed master server:master.example.com,60000,1353367210440
12/11/19 23:22:25 INFO util.ChaosMonkey: Sleeping for:5000
12/11/19 23:22:30 INFO util.ChaosMonkey: Starting master:master.example.com
12/11/19 23:22:30 INFO hbase.HBaseCluster: Starting Master on: master.example.com
12/11/19 23:22:30 INFO hbase.ClusterManager: Executing remote command: /homes/enis/code/hbase-0.94/bin/../bin/hbase-daemon.sh --config /homes/enis/code/hbase-0.94/bin/../conf start master , hostname:master.example.com
12/11/19 23:22:31 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:starting master, logging to /homes/enis/code/hbase-0.94/bin/../logs/hbase-enis-master-master.example.com.out
....
12/11/19 23:22:33 INFO util.ChaosMonkey: Started master: master.example.com,60000,1353367210440
12/11/19 23:22:33 INFO util.ChaosMonkey: Sleeping for:51321
12/11/19 23:23:24 INFO util.ChaosMonkey: Performing action: Restart random region server
12/11/19 23:23:24 INFO util.ChaosMonkey: Killing region server:rs3.example.com,60020,1353367027826
12/11/19 23:23:24 INFO hbase.HBaseCluster: Aborting RS: rs3.example.com,60020,1353367027826
12/11/19 23:23:24 INFO hbase.ClusterManager: Executing remote command: ps aux | grep regionserver | grep -v grep | tr -s ' ' | cut -d ' ' -f2 | xargs kill -s SIGKILL , hostname:rs3.example.com
12/11/19 23:23:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:23:25 INFO hbase.HBaseCluster: Waiting service:regionserver to stop: rs3.example.com,60020,1353367027826
12/11/19 23:23:25 INFO hbase.ClusterManager: Executing remote command: ps aux | grep regionserver | grep -v grep | tr -s ' ' | cut -d ' ' -f2 , hostname:rs3.example.com
12/11/19 23:23:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:23:25 INFO util.ChaosMonkey: Killed region server:rs3.example.com,60020,1353367027826. Reported num of rs:6
12/11/19 23:23:25 INFO util.ChaosMonkey: Sleeping for:60000
12/11/19 23:24:25 INFO util.ChaosMonkey: Starting region server:rs3.example.com
12/11/19 23:24:25 INFO hbase.HBaseCluster: Starting RS on: rs3.example.com
12/11/19 23:24:25 INFO hbase.ClusterManager: Executing remote command: /homes/enis/code/hbase-0.94/bin/../bin/hbase-daemon.sh --config /homes/enis/code/hbase-0.94/bin/../conf start regionserver , hostname:rs3.example.com
12/11/19 23:24:26 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:starting regionserver, logging to /homes/enis/code/hbase-0.94/bin/../logs/hbase-enis-regionserver-rs3.example.com.out

12/11/19 23:24:27 INFO util.ChaosMonkey: Started region server:rs3.example.com,60020,1353367027826. Reported num of rs:6
</pre><p>

As you can see from the log, ChaosMonkey started the default PeriodicRandomActionPolicy, which is configured with all the available actions, and ran RestartActiveMaster and RestartRandomRs actions. ChaosMonkey tool, if run from command line, will keep on running until the process is killed.
</p></div></div></div><div class="section" title="1.8.&nbsp;Maven Build Commands"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="maven.build.commands"></a>1.8.&nbsp;Maven Build Commands</h2></div></div></div><p>All commands executed from the local HBase project directory.
       </p><p>Note: use Maven 3 (Maven 2 may work but we suggest you use Maven 3).
       </p><div class="section" title="1.8.1.&nbsp;Compile"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commands.compile"></a>1.8.1.&nbsp;Compile</h3></div></div></div><pre class="programlisting">
mvn compile
          </pre></div><div class="section" title="1.8.2.&nbsp;Running all or individual Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commands.unitall"></a>1.8.2.&nbsp;Running all or individual Unit Tests</h3></div></div></div><p>See the <a class="xref" href="#hbase.unittests.cmds" title="1.7.3.&nbsp;Running tests">Section&nbsp;1.7.3, &#8220;Running tests&#8221;</a> section
          above in <a class="xref" href="#hbase.unittests" title="1.7.2.&nbsp;Unit Tests">Section&nbsp;1.7.2, &#8220;Unit Tests&#8221;</a></p></div><div class="section" title="1.8.3.&nbsp;Building against various hadoop versions."><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.hadoop"></a>1.8.3.&nbsp;Building against various hadoop versions.</h3></div></div></div><p>As of 0.96, Apache HBase supports building against Apache Hadoop versions: 1.0.3, 2.0.0-alpha and 3.0.0-SNAPSHOT.
          By default, we will build with Hadoop-1.0.3. To change the version to run with Hadoop-2.0.0-alpha, you would run:</p><pre class="programlisting">mvn -Dhadoop.profile=2.0 ...</pre><p>
         That is, designate build with hadoop.profile 2.0.  Pass 2.0 for hadoop.profile to build against hadoop 2.0.
         Tests may not all pass as of this writing so you may need to pass <code class="code">-DskipTests</code> unless you are inclined
          to fix the failing tests.</p><p>
         Similarly, for 3.0, you would just replace the profile value. Note that Hadoop-3.0.0-SNAPSHOT does not currently have a deployed maven artificat - you will need to build and install your own in your local maven repository if you want to run against this profile.
         </p><p>
         In earilier verions of Apache HBase, you can build against older versions of Apache Hadoop, notably, Hadoop 0.22.x and 0.23.x.
         If you are running, for example HBase-0.94 and wanted to build against Hadoop 0.23.x, you would run with:</p><pre class="programlisting">mvn -Dhadoop.profile=22 ...</pre></div></div><div class="section" title="1.9.&nbsp;Getting Involved"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="getting.involved"></a>1.9.&nbsp;Getting Involved</h2></div></div></div><p>Apache HBase gets better only when people contribute!
        </p><p>As Apache HBase is an Apache Software Foundation project, see <a class="xref" href="#">???</a> for more information about how the ASF functions.
        </p><div class="section" title="1.9.1.&nbsp;Mailing Lists"><div class="titlepage"><div><div><h3 class="title"><a name="mailing.list"></a>1.9.1.&nbsp;Mailing Lists</h3></div></div></div><p>Sign up for the dev-list and the user-list.  See the
          <a class="link" href="http://hbase.apache.org/mail-lists.html" target="_top">mailing lists</a> page.
          Posing questions - and helping to answer other people's questions - is encouraged!
          There are varying levels of experience on both lists so patience and politeness are encouraged (and please
          stay on topic.)
          </p></div><div class="section" title="1.9.2.&nbsp;Jira"><div class="titlepage"><div><div><h3 class="title"><a name="jira"></a>1.9.2.&nbsp;Jira</h3></div></div></div><p>Check for existing issues in <a class="link" href="https://issues.apache.org/jira/browse/HBASE" target="_top">Jira</a>.
          If it's either a new feature request, enhancement, or a bug, file a ticket.
          </p><div class="section" title="1.9.2.1.&nbsp;Jira Priorities"><div class="titlepage"><div><div><h4 class="title"><a name="jira.priorities"></a>1.9.2.1.&nbsp;Jira Priorities</h4></div></div></div><p>The following is a guideline on setting Jira issue priorities:
                </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Blocker: Should only be used if the issue WILL cause data loss or cluster instability reliably.</li><li class="listitem">Critical: The issue described can cause data loss or cluster instability in some cases.</li><li class="listitem">Major: Important but not tragic issues, like updates to the client API that will add a lot of much-needed functionality or significant
                bugs that need to be fixed but that don't cause data loss.</li><li class="listitem">Minor: Useful enhancements and annoying but not damaging bugs.</li><li class="listitem">Trivial: Useful enhancements but generally cosmetic.</li></ul></div><p>
             </p></div><div class="section" title="1.9.2.2.&nbsp;Code Blocks in Jira Comments"><div class="titlepage"><div><div><h4 class="title"><a name="submitting.patches.jira.code"></a>1.9.2.2.&nbsp;Code Blocks in Jira Comments</h4></div></div></div><p>A commonly used macro in Jira is {code}. If you do this in a Jira comment...
</p><pre class="programlisting">
{code}
   code snippet
{code}
</pre><p>
              ... Jira will format the code snippet like code, instead of a regular comment.  It improves readability.
          </p></div></div></div><div class="section" title="1.10.&nbsp;Developing"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="developing"></a>1.10.&nbsp;Developing</h2></div></div></div><div class="section" title="1.10.1.&nbsp;Codelines"><div class="titlepage"><div><div><h3 class="title"><a name="codelines"></a>1.10.1.&nbsp;Codelines</h3></div></div></div><p>Most development is done on TRUNK.  However, there are branches for minor releases (e.g., 0.90.1, 0.90.2, and 0.90.3 are on the 0.90 branch).</p><p>If you have any questions on this just send an email to the dev dist-list.</p></div><div class="section" title="1.10.2.&nbsp;Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="unit.tests"></a>1.10.2.&nbsp;Unit Tests</h3></div></div></div><p>In HBase we use <a class="link" href="http://junit.org" target="_top">JUnit</a> 4.
            If you need to run miniclusters of HDFS, ZooKeeper, HBase, or MapReduce testing,
            be sure to checkout the <code class="classname">HBaseTestingUtility</code>.
            Alex Baranau of Sematext describes how it can be used in
            <a class="link" href="http://blog.sematext.com/2010/08/30/hbase-case-study-using-hbasetestingutility-for-local-testing-development/" target="_top">HBase Case-Study: Using HBaseTestingUtility for Local Testing and Development</a> (2010).
          </p><div class="section" title="1.10.2.1.&nbsp;Mockito"><div class="titlepage"><div><div><h4 class="title"><a name="mockito"></a>1.10.2.1.&nbsp;Mockito</h4></div></div></div><p>Sometimes you don't need a full running server
              unit testing.  For example, some methods can make do with a
              a <code class="classname">org.apache.hadoop.hbase.Server</code> instance
              or a <code class="classname">org.apache.hadoop.hbase.master.MasterServices</code>
              Interface reference rather than a full-blown
              <code class="classname">org.apache.hadoop.hbase.master.HMaster</code>.
              In these cases, you maybe able to get away with a mocked
              <code class="classname">Server</code> instance.  For example:
              </p><pre class="programlisting">
              TODO...
              </pre><p>
           </p></div></div><div class="section" title="1.10.3.&nbsp;Code Standards"><div class="titlepage"><div><div><h3 class="title"><a name="code.standards"></a>1.10.3.&nbsp;Code Standards</h3></div></div></div><p>See <a class="xref" href="#eclipse.code.formatting" title="1.2.1.1.&nbsp;Code Formatting">Section&nbsp;1.2.1.1, &#8220;Code Formatting&#8221;</a> and <a class="xref" href="#common.patch.feedback" title="1.11.5.&nbsp;Common Patch Feedback">Section&nbsp;1.11.5, &#8220;Common Patch Feedback&#8221;</a>.
           </p><p>Also, please pay attention to the interface stability/audience classifications that you
           will see all over our code base.   They look like this at the head of the class:
           </p><pre class="programlisting">@InterfaceAudience.Public
@InterfaceStability.Stable</pre><p>
           </p><p>If the <code class="classname">InterfaceAudience</code> is <code class="varname">Private</code>,
           we can change the class (and we do not need to include a <code class="classname">InterfaceStability</code> mark).
           If a class is marked <code class="varname">Public</code> but its <code class="classname">InterfaceStability</code>
           is marked <code class="varname">Unstable</code>, we can change it. If it's
           marked <code class="varname">Public</code>/<code class="varname">Evolving</code>, we're allowed to change it
           but should try not to. If it's <code class="varname">Public</code> and <code class="varname">Stable</code>
           we can't change it without a deprecation path or with a really GREAT reason.</p><p>When you add new classes, mark them with the annotations above if publically accessible.
           If you are not cleared on how to mark your additions, ask up on the dev list.
           </p><p>This convention comes from our parent project Hadoop.</p></div><div class="section" title="1.10.4.&nbsp;Invariants"><div class="titlepage"><div><div><h3 class="title"><a name="design.invariants"></a>1.10.4.&nbsp;Invariants</h3></div></div></div><p>We don't have many but what we have we list below.  All are subject to challenge of
           course but until then, please hold to the rules of the road.
           </p><div class="section" title="1.10.4.1.&nbsp;No permanent state in ZooKeeper"><div class="titlepage"><div><div><h4 class="title"><a name="design.invariants.zk.data"></a>1.10.4.1.&nbsp;No permanent state in ZooKeeper</h4></div></div></div><p>ZooKeeper state should transient (treat it like memory). If deleted, hbase
          should be able to recover and essentially be in the same state<sup>[<a name="d4590e1064" href="#ftn.d4590e1064" class="footnote">1</a>]</sup>.
          </p></div></div><div class="section" title="1.10.5.&nbsp;Running In-Situ"><div class="titlepage"><div><div><h3 class="title"><a name="run.insitu"></a>1.10.5.&nbsp;Running In-Situ</h3></div></div></div><p>If you are developing Apache HBase, frequently it is useful to test your changes against a more-real cluster than what you find in unit tests. In this case, HBase can be run directly from the source in local-mode.
           All you need to do is run:
           </p><pre class="programlisting">${HBASE_HOME}/bin/start-hbase.sh</pre><p>
           This will spin up a full local-cluster, just as if you had packaged up HBase and installed it on your machine.
           </p><p>Keep in mind that you will need to have installed HBase into your local maven repository for the in-situ cluster to work properly. That is, you will need to run:</p><pre class="programlisting">mvn clean install -DskipTests</pre><p>to ensure that maven can find the correct classpath and dependencies. Generally, the above command
           is just a good thing to try running first, if maven is acting oddly.</p></div></div><div class="section" title="1.11.&nbsp;Submitting Patches"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="submitting.patches"></a>1.11.&nbsp;Submitting Patches</h2></div></div></div><p>If you are new to submitting patches to open source or new to submitting patches to Apache,
          I'd suggest you start by reading the <a class="link" href="http://commons.apache.org/patches.html" target="_top">On Contributing Patches</a>
          page from <a class="link" href="http://commons.apache.org/" target="_top">Apache Commons Project</a>.  Its a nice overview that
          applies equally to the Apache HBase Project.</p><div class="section" title="1.11.1.&nbsp;Create Patch"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.create"></a>1.11.1.&nbsp;Create Patch</h3></div></div></div><p>See the aforementioned Apache Commons link for how to make patches against a checked out subversion
          repository.  Patch files can also be easily generated from Eclipse, for example by selecting "Team -&gt; Create Patch".
          Patches can also be created by git diff and svn diff.
          </p><p>Please submit one patch-file per Jira.  For example, if multiple files are changed make sure the
          selected resource when generating the patch is a directory.  Patch files can reflect changes in multiple files. </p><p>Make sure you review <a class="xref" href="#eclipse.code.formatting" title="1.2.1.1.&nbsp;Code Formatting">Section&nbsp;1.2.1.1, &#8220;Code Formatting&#8221;</a> for code style. </p></div><div class="section" title="1.11.2.&nbsp;Patch File Naming"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.naming"></a>1.11.2.&nbsp;Patch File Naming</h3></div></div></div><p>The patch file should have the Apache HBase Jira ticket in the name.  For example, if a patch was submitted for <code class="filename">Foo.java</code>, then
          a patch file called <code class="filename">Foo_HBASE_XXXX.patch</code> would be acceptable where XXXX is the Apache HBase Jira number.
          </p><p>If you generating from a branch, then including the target branch in the filename is advised, e.g., <code class="filename">HBASE-XXXX-0.90.patch</code>.
          </p></div><div class="section" title="1.11.3.&nbsp;Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.tests"></a>1.11.3.&nbsp;Unit Tests</h3></div></div></div><p>Yes, please.  Please try to include unit tests with every code patch (and especially new classes and large changes).
            Make sure unit tests pass locally before submitting the patch.</p><p>Also, see <a class="xref" href="#mockito" title="1.10.2.1.&nbsp;Mockito">Section&nbsp;1.10.2.1, &#8220;Mockito&#8221;</a>.</p><p>If you are creating a new unit test class, notice how other unit test classes have classification/sizing
            annotations at the top and a static method on the end.  Be sure to include these in any new unit test files
            you generate.  See <a class="xref" href="#hbase.tests" title="1.7.&nbsp;Tests">Section&nbsp;1.7, &#8220;Tests&#8221;</a> for more on how the annotations work.
            </p></div><div class="section" title="1.11.4.&nbsp;Attach Patch to Jira"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.jira"></a>1.11.4.&nbsp;Attach Patch to Jira</h3></div></div></div><p>The patch should be attached to the associated Jira ticket "More Actions -&gt; Attach Files".  Make sure you click the
            ASF license inclusion, otherwise the patch can't be considered for inclusion.
            </p><p>Once attached to the ticket, click "Submit Patch" and
            the status of the ticket will change.  Committers will review submitted patches for inclusion into the codebase.  Please
            understand that not every patch may get committed, and that feedback will likely be provided on the patch.  Fear not, though,
            because the Apache HBase community is helpful!
            </p></div><div class="section" title="1.11.5.&nbsp;Common Patch Feedback"><div class="titlepage"><div><div><h3 class="title"><a name="common.patch.feedback"></a>1.11.5.&nbsp;Common Patch Feedback</h3></div></div></div><p>The following items are representative of common patch feedback. Your patch process will go faster if these are
          taken into account <span class="emphasis"><em>before</em></span> submission.
          </p><p>
          See the <a class="link" href="http://www.oracle.com/technetwork/java/codeconv-138413.html" target="_top">Java coding standards</a>
          for more information on coding conventions in Java.
          </p><div class="section" title="1.11.5.1.&nbsp;Space Invaders"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.space.invaders"></a>1.11.5.1.&nbsp;Space Invaders</h4></div></div></div><p>Rather than do this...
</p><pre class="programlisting">
if ( foo.equals( bar ) ) {     // don't do this
</pre><p>
			... do this instead...
</p><pre class="programlisting">
if (foo.equals(bar)) {
</pre><p>
          </p><p>Also, rather than do this...
</p><pre class="programlisting">
foo = barArray[ i ];     // don't do this
</pre><p>
			... do this instead...
</p><pre class="programlisting">
foo = barArray[i];
</pre><p>
          </p></div><div class="section" title="1.11.5.2.&nbsp;Auto Generated Code"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.autogen"></a>1.11.5.2.&nbsp;Auto Generated Code</h4></div></div></div><p>Auto-generated code in Eclipse often looks like this...
</p><pre class="programlisting">
 public void readFields(DataInput arg0) throws IOException {    // don't do this
   foo = arg0.readUTF();                                       // don't do this
</pre><p>
			... do this instead ...
</p><pre class="programlisting">
 public void readFields(DataInput di) throws IOException {
   foo = di.readUTF();
</pre><p>
           See the difference?  'arg0' is what Eclipse uses for arguments by default.
           </p></div><div class="section" title="1.11.5.3.&nbsp;Long Lines"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.longlines"></a>1.11.5.3.&nbsp;Long Lines</h4></div></div></div><p>
            Keep lines less than 100 characters.
</p><pre class="programlisting">
Bar bar = foo.veryLongMethodWithManyArguments(argument1, argument2, argument3, argument4, argument5, argument6, argument7, argument8, argument9);  // don't do this
</pre><p>
			... do something like this instead ...
</p><pre class="programlisting">
Bar bar = foo.veryLongMethodWithManyArguments(
 argument1, argument2, argument3,argument4, argument5, argument6, argument7, argument8, argument9);
</pre><p>
           </p></div><div class="section" title="1.11.5.4.&nbsp;Trailing Spaces"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.trailingspaces"></a>1.11.5.4.&nbsp;Trailing Spaces</h4></div></div></div><p>
            This happens more than people would imagine.
</p><pre class="programlisting">
Bar bar = foo.getBar();     &lt;--- imagine there's an extra space(s) after the semicolon instead of a line break.
</pre><p>
            Make sure there's a line-break after the end of your code, and also avoid lines that have nothing
            but whitespace.
            </p></div><div class="section" title="1.11.5.5.&nbsp;Implementing Writable"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.writable"></a>1.11.5.5.&nbsp;Implementing Writable</h4></div></div></div><div class="note" title="Applies pre-0.96 only" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Applies pre-0.96 only</h3><p>In 0.96, HBase moved to protobufs.  The below section on Writables
                    applies to 0.94.x and previous, not to 0.96 and beyond.
                </p></div><p>Every class returned by RegionServers must implement <code class="code">Writable</code>.  If you
            are creating a new class that needs to implement this interface, don't forget the default constructor.
            </p></div><div class="section" title="1.11.5.6.&nbsp;Javadoc"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.javadoc"></a>1.11.5.6.&nbsp;Javadoc</h4></div></div></div><p>This is also a very common feedback item.  Don't forget Javadoc!
                </p><p>Javadoc warnings are checked during precommit. If the precommit tool gives you a '-1',
                    please fix the javadoc issue. Your patch won't be committed if it adds such warnings.
                </p><p>
            </p></div><div class="section" title="1.11.5.7.&nbsp;Findbugs"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.findbugs"></a>1.11.5.7.&nbsp;Findbugs</h4></div></div></div><p>
                    Findbugs is used to detect common bugs pattern. As Javadoc, it is checked during
                    the precommit build up on Apache's Jenkins, and as with Javadoc, please fix them.
                    You can run findbugs locally with 'mvn findbugs:findbugs': it will generate the
                    findbugs files locally.  Sometimes, you may have to write code smarter than
                    Findbugs. You can annotate your code to tell Findbugs you know what you're
                    doing, by annotating your class with:
                    </p><pre class="programlisting">@edu.umd.cs.findbugs.annotations.SuppressWarnings(
                    value="HE_EQUALS_USE_HASHCODE",
                    justification="I know what I'm doing")</pre><p>
            </p><p>
                    Note that we're using the apache licensed version of the annotations.
            </p></div><div class="section" title="1.11.5.8.&nbsp;Javadoc - Useless Defaults"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.javadoc.defaults"></a>1.11.5.8.&nbsp;Javadoc - Useless Defaults</h4></div></div></div><p>Don't just leave the @param arguments the way your IDE generated them.  Don't do this...
</p><pre class="programlisting">
  /**
   *
   * @param bar             &lt;---- don't do this!!!!
   * @return                &lt;---- or this!!!!
   */
  public Foo getFoo(Bar bar);
</pre><p>
            ... either add something descriptive to the @param and @return lines, or just remove them.
            But the preference is to add something descriptive and useful.
            </p></div><div class="section" title="1.11.5.9.&nbsp;One Thing At A Time, Folks"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.onething"></a>1.11.5.9.&nbsp;One Thing At A Time, Folks</h4></div></div></div><p>If you submit a patch for one thing, don't do auto-reformatting or unrelated reformatting of code on a completely
            different area of code.
            </p><p>Likewise, don't add unrelated cleanup or refactorings outside the scope of your Jira.
            </p></div><div class="section" title="1.11.5.10.&nbsp;Ambigious Unit Tests"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.tests"></a>1.11.5.10.&nbsp;Ambigious Unit Tests</h4></div></div></div><p>Make sure that you're clear about what you are testing in your unit tests and why.
            </p></div></div><div class="section" title="1.11.6.&nbsp;ReviewBoard"><div class="titlepage"><div><div><h3 class="title"><a name="reviewboard"></a>1.11.6.&nbsp;ReviewBoard</h3></div></div></div><p>Larger patches should go through <a class="link" href="http://reviews.apache.org" target="_top">ReviewBoard</a>.
          </p><p>For more information on how to use ReviewBoard, see
           <a class="link" href="http://www.reviewboard.org/docs/manual/1.5/" target="_top">the ReviewBoard documentation</a>.
          </p></div><div class="section" title="1.11.7.&nbsp;Committing Patches"><div class="titlepage"><div><div><h3 class="title"><a name="committing.patches"></a>1.11.7.&nbsp;Committing Patches</h3></div></div></div><p>
          Committers do this.  See <a class="link" href="http://wiki.apache.org/hadoop/Hbase/HowToCommit" target="_top">How To Commit</a> in the Apache HBase wiki.
          </p><p>Commiters will also resolve the Jira, typically after the patch passes a build.
          </p><div class="section" title="1.11.7.1.&nbsp;Committers are responsible for making sure commits do not break the build or tests"><div class="titlepage"><div><div><h4 class="title"><a name="committer.tests"></a>1.11.7.1.&nbsp;Committers are responsible for making sure commits do not break the build or tests</h4></div></div></div><p>
              If a committer commits a patch it is their responsibility
              to make sure it passes the test suite.  It is helpful
              if contributors keep an eye out that their patch
              does not break the hbase build and/or tests but ultimately,
              a contributor cannot be expected to be up on the
              particular vagaries and interconnections that occur
              in a project like hbase.  A committer should.
            </p></div></div></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d4590e1064" href="#d4590e1064" class="para">1</a>] </sup>There are currently
          a few exceptions that we need to fix around whether a table is enabled or disabled</p></div></div></div></body></html>